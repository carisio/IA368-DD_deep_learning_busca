{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33412e06",
   "metadata": {},
   "source": [
    "# Aula 8 - Solução dos exercícios - Parte 1 - Geração de queries\n",
    "\n",
    "Leandro Carísio Fernandes\n",
    "\n",
    "<br>\n",
    "\n",
    "Objetivo: gerar dataset para treino de modelos de buscas usando a técnica do InPars e avaliar um modelo reranqueador treinado neste dataset no TREC-COVID:\n",
    "\n",
    "    - Entrada: 3-5 exemplos few-shot + documento amostrado da coleção do TREC-COVID\n",
    "    - Saída: query que seja relevante para o documento amostrado\n",
    "    - É opcional fazer a etapa de filtragem usando as queries de maior prob descrita no Artigo.   \n",
    "    - Como modelo gerador, use um dos seguintes modelos:\n",
    "        - ChatGPT-3.5-turbo: ~1 USD para cada 1k exemplos\n",
    "        - FLAN-T5 (base, large ou XL), LLAMA-(7,13B), Alpaca-(7/13B), que são possiveis de rodar no Colab Pro.\n",
    "        - Também tem a inference-api da HF: https://huggingface.co/inference-api.\n",
    "        - Com exceção do LLAMA, é possivel usar zero-shot ao inves de few-shot.\n",
    "    - Dado 1k-10k pares <query sintética; documento>, treinar um modelo reranqueador miniLM igual ao da aula 2/3.\n",
    "    - Exemplos negativos (i.e., <query sintética; doc não relevant) vem do BM25: dado a query sintetica, retornar top 1000 com o BM25, e amostrar aleatoriamente alguns documentos como negativo\n",
    "    - Começar treino do miniLM já treinado no MS MARCO\n",
    "\n",
    "Avaliar no TREC-COVID e comparar com o reranqueador apenas treinado no MSMARCO\n",
    "\n",
    "Nota: Também usar o dataset dos colegas para obter diversidade de exemplos: Assim que tiver gerado o dataset sintético, favor colocar na planilha, assim outras pessoas podem usa-lo.\n",
    "\n",
    "    - Para aumentar a aleatoriedade, seed usada deve o seu numero na planilha.\n",
    "\n",
    "Colocar dataset no formato jsonlines:\n",
    "{\"query\": query, \"positive_doc_id\": doc_id, \"negative_doc_ids\": [opcional]}\\n \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733364d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "url_trec_covid = 'https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/trec-covid.zip'\n",
    "\n",
    "\n",
    "!pip install openai -q\n",
    "!pip install wget -q\n",
    "!pip install -qU huggingface_hub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39d004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processado 0 documentos\n",
      "Processado 10000 documentos\n",
      "Processado 20000 documentos\n",
      "Processado 30000 documentos\n",
      "Processado 40000 documentos\n",
      "Processado 50000 documentos\n",
      "Processado 60000 documentos\n",
      "Processado 70000 documentos\n",
      "Processado 80000 documentos\n",
      "Processado 90000 documentos\n",
      "Processado 100000 documentos\n",
      "Processado 110000 documentos\n",
      "Processado 120000 documentos\n",
      "Processado 130000 documentos\n",
      "Processado 140000 documentos\n",
      "Processado 150000 documentos\n",
      "Processado 160000 documentos\n",
      "Processado 170000 documentos\n",
      "CPU times: total: 1.52 s\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "import wget\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "    \n",
    "if not Path('./collections/trec-covid.zip').is_file():\n",
    "    !mkdir collections\n",
    "    wget.download(url_trec_covid, out='./collections/')\n",
    "    with zipfile.ZipFile('./collections/trec-covid.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./collections/')\n",
    "\n",
    "    \n",
    "def carrega_corpus_trec_covid():\n",
    "    retorno = []\n",
    "    with open('./collections/trec-covid/corpus.jsonl') as corpus:\n",
    "        for i, line in enumerate(corpus):\n",
    "            doc = json.loads(line)\n",
    "            retorno.append( doc )\n",
    "            if (i % 10000 == 0):\n",
    "                print(f'Processado {i} documentos')\n",
    "    return retorno\n",
    "\n",
    "corpus_trec_covid = carrega_corpus_trec_covid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16d4e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('API_KEY_OPENAI')\n",
    "\n",
    "def adiciona_query_gpt_no_doc(idx):\n",
    "    texto = corpus_trec_covid[idx]['text']\n",
    "\n",
    "    msg = f\"Formulate ONE query for the following passage. \\\n",
    "            Consider how a human use a search engine. Randomly choose if your question starts with what, how, why or which. \\\n",
    "            \\n\\n\\\n",
    "            {texto}\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You're cataloging documents and need to associate queries with document passages.\"},\n",
    "                    {\"role\": \"user\", \"content\": msg}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=500)\n",
    "\n",
    "    corpus_trec_covid[idx]['query'] = response['choices'][0]['message']['content']\n",
    "\n",
    "    \n",
    "def adiciona_query_no_corpus(nome_arquivo, indices):\n",
    "    with open(nome_arquivo, 'a', encoding='utf-8') as arquivo:\n",
    "        for i, idx in enumerate(indices):\n",
    "            adiciona_query_gpt_no_doc(idx)\n",
    "            \n",
    "            doc = {\"positive_doc_id\": corpus_trec_covid[idx][\"_id\"], \"query\": corpus_trec_covid[idx]['query']}\n",
    "            \n",
    "            arquivo.write(f\"{json.dumps(doc)}\\n\")\n",
    "            \n",
    "            if i % 20 == 0:\n",
    "                print(f'{i} documentos processados')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7168f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(8)\n",
    "\n",
    "indices_candidatos = np.random.randint(0, high=len(corpus_trec_covid)-1, size=2000)\n",
    "indices = [i for i in indices_candidatos if len(corpus_trec_covid[i]['text']) > 300]\n",
    "indices = indices[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a08b3e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 documentos processados\n",
      "20 documentos processados\n",
      "40 documentos processados\n",
      "60 documentos processados\n",
      "80 documentos processados\n",
      "100 documentos processados\n",
      "120 documentos processados\n",
      "140 documentos processados\n",
      "160 documentos processados\n",
      "180 documentos processados\n",
      "200 documentos processados\n",
      "220 documentos processados\n",
      "240 documentos processados\n",
      "260 documentos processados\n",
      "280 documentos processados\n",
      "300 documentos processados\n",
      "320 documentos processados\n",
      "340 documentos processados\n",
      "360 documentos processados\n",
      "380 documentos processados\n"
     ]
    }
   ],
   "source": [
    "#adiciona_query_no_corpus('leandro_carisio_20230428_01.jsonl', indices[600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3b002cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 documentos processados\n"
     ]
    }
   ],
   "source": [
    "#adiciona_query_no_corpus('leandro_carisio_20230428_01.jsonl', indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f79e2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba25390df574745b5a9ac20f1674660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef6dbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e25961c7f54827abcac4e7e098e9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset trec-covid-experiment/default to C:/Users/caris/.cache/huggingface/datasets/unicamp-dl___trec-covid-experiment/default/0.0.0/e8f516bf1f4cd83299422fabc7d8b2baec58a8fe01f2ff03afe3db652b47a1b8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891b9a92c81d42049d63d598eddd2685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e36b5b06716484488c386570880a236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/309 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8523738d6ee14710a210282166203582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/346 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42141c71b74f4629b643144d166acc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7b986b31c049f1bca5e95170959c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/173k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating example split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating example2 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eduseiti_100_queries_expansion_20230428_01 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating leandro_carisio_20230428_01 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset trec-covid-experiment downloaded and prepared to C:/Users/caris/.cache/huggingface/datasets/unicamp-dl___trec-covid-experiment/default/0.0.0/e8f516bf1f4cd83299422fabc7d8b2baec58a8fe01f2ff03afe3db652b47a1b8. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950d3c111f0c4b9db179ad1c4a4d3be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.load_dataset('unicamp-dl/trec-covid-experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53c6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91c0efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>positive_doc_id</th>\n",
       "      <th>negative_doc_ids</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a example query 1</td>\n",
       "      <td>doc1</td>\n",
       "      <td>[xxx, yyy, zzz]</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is another example query</td>\n",
       "      <td>doc2</td>\n",
       "      <td>[aaa, bbb, ccc]</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Example of query with no negative doc_ids</td>\n",
       "      <td>doc2</td>\n",
       "      <td>[]</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a example query 1 (file 2)</td>\n",
       "      <td>doc12222</td>\n",
       "      <td>[xxx, yyy, zzz]</td>\n",
       "      <td>example2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is another example query (file 2)</td>\n",
       "      <td>doc12345</td>\n",
       "      <td>[aaa, bbb, ccc]</td>\n",
       "      <td>example2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>What are the recent nanoscience advancements f...</td>\n",
       "      <td>8nwwhu9d</td>\n",
       "      <td>[]</td>\n",
       "      <td>leandro_carisio_20230428_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>What is the role of neutrophils in the pathoge...</td>\n",
       "      <td>c4wy70hf</td>\n",
       "      <td>[]</td>\n",
       "      <td>leandro_carisio_20230428_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>Why is pulmonary metastasectomy widely and inc...</td>\n",
       "      <td>xv47an66</td>\n",
       "      <td>[]</td>\n",
       "      <td>leandro_carisio_20230428_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>How does the use of concurrent suction while d...</td>\n",
       "      <td>bjozlk01</td>\n",
       "      <td>[]</td>\n",
       "      <td>leandro_carisio_20230428_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>What is SARS-CoV-2 and how is it transmitted?</td>\n",
       "      <td>0iq9s94n</td>\n",
       "      <td>[]</td>\n",
       "      <td>leandro_carisio_20230428_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query positive_doc_id  \\\n",
       "0                             This is a example query 1            doc1   \n",
       "1                         This is another example query            doc2   \n",
       "2             Example of query with no negative doc_ids            doc2   \n",
       "3                    This is a example query 1 (file 2)        doc12222   \n",
       "4                This is another example query (file 2)        doc12345   \n",
       "...                                                 ...             ...   \n",
       "1465  What are the recent nanoscience advancements f...        8nwwhu9d   \n",
       "1466  What is the role of neutrophils in the pathoge...        c4wy70hf   \n",
       "1467  Why is pulmonary metastasectomy widely and inc...        xv47an66   \n",
       "1468  How does the use of concurrent suction while d...        bjozlk01   \n",
       "1469      What is SARS-CoV-2 and how is it transmitted?        0iq9s94n   \n",
       "\n",
       "     negative_doc_ids                       origin  \n",
       "0     [xxx, yyy, zzz]                      example  \n",
       "1     [aaa, bbb, ccc]                      example  \n",
       "2                  []                      example  \n",
       "3     [xxx, yyy, zzz]                     example2  \n",
       "4     [aaa, bbb, ccc]                     example2  \n",
       "...               ...                          ...  \n",
       "1465               []  leandro_carisio_20230428_01  \n",
       "1466               []  leandro_carisio_20230428_01  \n",
       "1467               []  leandro_carisio_20230428_01  \n",
       "1468               []  leandro_carisio_20230428_01  \n",
       "1469               []  leandro_carisio_20230428_01  \n",
       "\n",
       "[1470 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((v.to_pandas().assign(origin=k) for k,v in ds.items()),\n",
    "               ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105529f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['example', 'example2',\n",
       "       'eduseiti_100_queries_expansion_20230428_01',\n",
       "       'leandro_carisio_20230428_01'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df.origin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
