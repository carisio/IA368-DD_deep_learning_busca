{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ByD6ARbqmJ"
      },
      "source": [
        "## Aula 1 - Solução dos exercícios\n",
        "Leandro Carísio Fernandes\n",
        "\n",
        "<br>\n",
        "\n",
        "Enunciado do exercício da semana:\n",
        "\n",
        "1. Usar o BM25 implementado pelo pyserini para buscar queries no TREC-DL 2020 ([Documentação de referência](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md))\n",
        "2. Implementar um buscador booleano/bag-of-words.\n",
        "3. Implementar um buscador com TF-IDF\n",
        "4. Avaliar implementações 1, 2, e 3 no TREC-DL 2020 e calcular o nDCG@10\n",
        "\n",
        "Nos itens 2 e 3: (i) Fazer uma implementação que suporta buscar eficientemente milhões de documentos e (ii) Não se pode usar bibliotecas como sklearn, que já implementam o BoW e TF-IDF.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "### I. Conceitos\n",
        "\n",
        "Inicialmente fiquei muito perdido com toda essa história. O que é anserini? pyserini? MSMARCO? Passage? Documents? TREC-DL 2020? Como isso tudo se conecta?\n",
        "\n",
        "Então vale a pena começar vendo o que é cada uma dessas coisas:\n",
        "\n",
        "1. Passage/documents\n",
        "\n",
        "  Perguntei ao ChatGPT \"what is the difference between document and passage (context: information retrieval)?\" e a resposta foi:\n",
        "\n",
        "  <br>\n",
        "\n",
        "  \"In the context of information retrieval, a \"document\" refers to a complete unit of text, such as a full article, a book, or a web page. *A document contains multiple passages or sections of text that may or may not be relevant to a user's query*.\n",
        "\n",
        "  On the other hand, *a \"passage\" refers to a shorter section of text*, usually a few sentences long, that is directly relevant to a user's query. Passages are often extracted from larger documents and presented to the user as the most relevant part of the document for their query. (...)\"\n",
        "\n",
        "  <br>\n",
        "\n",
        "  \"Passage\" parece ser apenas trechos de texto mesmo. Isso pode ser visto também no [survey](https://arxiv.org/pdf/2010.06467.pdf). Por exemplo (capítulo 2):\n",
        "\n",
        "  <br>\n",
        "\n",
        "  \"*Approaches to segmenting documents into passages* for ranking purposes and integrating evidence from multiple document granularities — commonly referred to as passage retrieval — was an active area of research in the 1990s (...).\"\n",
        "\n",
        "<br>\n",
        "\n",
        "2. MS MARCO\n",
        "\n",
        "  [De acordo com o site](https://microsoft.github.io/msmarco/):\n",
        "\n",
        "  <br>\n",
        "\n",
        "  \"Starting with a paper released at [NIPS 2016](https://arxiv.org/pdf/1611.09268.pdf), MS MARCO is a collection of datasets focused on deep learning in search.\n",
        "\n",
        "  The first dataset was a question answering dataset featuring 100,000 real Bing questions and a human generated answer. Since then we released a 1,000,000 question dataset, a natural langauge generation dataset, a passage ranking dataset, keyphrase extraction dataset, crawling dataset, and a conversational search.\n",
        "\n",
        "  (...)\n",
        "\n",
        "  \"Microsoft Machine Reading Comprehension (MS MARCO) is a collection of large scale datasets for deep learning related to Search. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated if they could summarize the answer.\"\n",
        "\n",
        "  <br>\n",
        "\n",
        "  Em suma, é uma coleção de bases de dados usadas para teste. Há a coleção msmarco-passage (passage) e a coleção msmarco-doc (documents)\n",
        "\n",
        "<br>\n",
        "\n",
        "3. Anserini, pyserini e TREC\n",
        "\n",
        "  Perguntei ao ChatGPT \"what is anserini?\" e a resposta foi:\n",
        "\n",
        "  <br>\n",
        "\n",
        "  \"Anserini is an open-source information retrieval toolkit developed jointly by the University of Waterloo and the University of Massachusetts Amherst. It provides a set of tools and algorithms for performing various tasks related to information retrieval, such as indexing, searching, and ranking of documents.\n",
        "\n",
        "  Anserini was developed specifically for the TREC (Text REtrieval Conference) competitions, which are annual conferences focused on information retrieval research. It was designed to be fast, efficient, and scalable, and to provide state-of-the-art retrieval models and evaluation tools.\n",
        "\n",
        "  Anserini supports a wide range of retrieval models, including classic models such as BM25 and language models like Dirichlet and Jelinek-Mercer smoothing. It also includes more recent neural models, such as the Conv-KNRM and the BERT-IR models, which have achieved state-of-the-art performance on various retrieval tasks.\n",
        "\n",
        "  In addition to supporting a variety of retrieval models, Anserini also provides tools for indexing large document collections, evaluating retrieval results using standard measures such as mean average precision (MAP) and normalized discounted cumulative gain (NDCG), and processing queries in different formats. (...)\"\n",
        "\n",
        "  <br>\n",
        "\n",
        "  Perguntei também \"how is pyserine related to the trec conference?\":\n",
        "\n",
        "  <br>\n",
        "\n",
        "  \"Pyserini is a Python interface to the Anserini information retrieval toolkit, which was developed by the University of Waterloo and the University of Massachusetts Amherst for the TREC (Text REtrieval Conference) competitions. TREC is an annual conference series focused on information retrieval research, where participants compete to develop the most effective algorithms for various tasks, such as document retrieval, passage retrieval, and question answering.\n",
        "\n",
        "  Anserini was developed specifically for the TREC 2018 Common Core Track, which aimed to provide a common testbed for research in document retrieval using a standard set of topics and relevance judgments. Since then, Anserini has been used for many other TREC tracks and has become a popular toolkit for information retrieval research.\n",
        "\n",
        "  Pyserini provides a convenient Python wrapper around the Anserini toolkit, allowing researchers to use Anserini's powerful retrieval models and evaluation tools in a Python environment. This makes it easier to experiment with different retrieval models and compare their performance on various datasets, including those used in TREC competitions. Therefore, Pyserini is a valuable tool for researchers who are interested in participating in the TREC conference or conducting information retrieval research more broadly.\"\n",
        "\n",
        "  <br>\n",
        "\n",
        "  Considerando essas respostas e uma consulta ao [site](https://trec.nist.gov/): Há uma conferência chamada TREC (Text REtrieval Conference) co-patrocinada pelo National Institute of Standards and Technology (NIST) e pelo U.S. Department of Defense. Essa conferência é anual e o objetivo é apoiar a pesquisa dentro da comunidade de recuperação de informação, fornecendo a infraestrutura necessária para avaliação em larga escala de metodologias de recuperação de texto.\n",
        "\n",
        "  Um workshop TREC consiste em um conjunto de trilhas (tracks), áreas de foco nas quais tarefas de recuperação específicas são definidas. [TREC-DL 2020](https://microsoft.github.io/msmarco/TREC-Deep-Learning-2020) é nome da trilha deep learning do ano 2020.\n",
        "\n",
        "<br>\n",
        "\n",
        "4. Conectando tudo:\n",
        "\n",
        "  A trilha TREC-DL 2020 tem duas tarefas: ranqueamento de trechos de texto (passage) e ranqueamento de documentos. Cada uma dessas tarefas usam \"a large human-generated set of training labels\" disponibilizado dentro da base MS MARCO (no caso da primeira, são 200 queries). E o Pyserini pode ser usado para acessar essa base e usar alguns modelos/métricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAS_tHxI3uJK"
      },
      "source": [
        "### II. Instalando o pyserini e testando:\n",
        "\n",
        "Inicialmente, vamos fazer a instalação do pyserini seguindo esses tutoriais:\n",
        "\n",
        "https://github.com/castorini/pyserini/blob/master/docs/installation.md\n",
        "\n",
        "https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04VGQRxxQiRr",
        "outputId": "190d50ae-84d3-417a-9a6c-8c59ebf4ad3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyserini in /usr/local/lib/python3.8/dist-packages (0.20.0)\n",
            "Requirement already satisfied: nmslib>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (2.1.1)\n",
            "Requirement already satisfied: lightgbm>=3.3.2 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.2.1)\n",
            "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.4.4)\n",
            "Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.26.1)\n",
            "Requirement already satisfied: sentencepiece>=0.1.95 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.1.97)\n",
            "Requirement already satisfied: onnxruntime>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.22.4)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.29.33)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.5.3)\n",
            "Requirement already satisfied: pyjnius>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.4.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (2.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (15.0.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.1.21)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.4.0->pyserini) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (8.1.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.4.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.25.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.10.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.6.0->pyserini) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.26.14)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.8/dist-packages (from coloredlogs->onnxruntime>=1.8.1->pyserini) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "CPU times: user 174 ms, sys: 40.2 ms, total: 214 ms\n",
            "Wall time: 19 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Se True, essa variável configura para gerar o índice da coleção MS MARCO usando o comando pyserini.index.lucene e salva o índice no Drive\n",
        "# Se False, considera que o índice já está salvo no Drive e lê ele direto de lá\n",
        "gerar_indice_pyserini = False\n",
        "\n",
        "# Se True, essa variável configura para gerar o índice que foi implementado neste notebook para a coleção MS MARCO e salva no Drive\n",
        "# Se False, considera que o índice já está salvo no Drive e apenas lê direto de lá e monta manualmente o objeto aqui\n",
        "gerar_indice_implementado = False\n",
        "\n",
        "# Já aproveita e monta logo o google drive pra ele solicitar a permissão de uma vez\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install pyserini\n",
        "!pip install torch\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ii576-Vyc3",
        "outputId": "3e00040f-1286-443a-f2d2-4aa14551d0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk 11.0.18 2023-01-17\n",
            "OpenJDK Runtime Environment (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.18+10-post-Ubuntu-0ubuntu120.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "# É necessário que seja a versão 11. Checa versão:\n",
        "!java --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b2zQi3eYkhX"
      },
      "source": [
        "Segundo o tutorial, \"to confirm that bag-of-words retrieval is working correctly, you can run the BM25 baseline on the MS MARCO passage ranking task\".\n",
        "\n",
        "Obs.: o comando abaixo vai baixar e gerar o índice. É demorado (~15min) e só usei ele apenas para seguir o roteiro e ver se a instalação das bibliotecas estava ok. Por isso está comentado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCSeVZ9cRDx4"
      },
      "outputs": [],
      "source": [
        "#!python -m pyserini.search \\\n",
        "#    --topics msmarco-passage-dev-subset \\\n",
        "#    --index msmarco-v1-passage \\\n",
        "#    --output run.msmarco-passage.txt \\\n",
        "#    --output-format msmarco \\\n",
        "#    --bm25\n",
        "\n",
        "#!python -m pyserini.eval.msmarco_passage_eval msmarco-passage-dev-subset run.msmarco-passage.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tViyRfAbaiAf"
      },
      "source": [
        "Até aqui parece ok a instalação padrão.\n",
        "\n",
        "Agora vamos seguir o tutorial passado como exemplo, BM25 Baseline for MS MARCO Passage Retrieval.\n",
        "\n",
        "A ideia aqui é baixar o MS MARCO, descompactá-lo e gerar o índice.\n",
        "\n",
        "O primeiro passo é baixar o arquivo collectionandqueries.tar.gz e descompactá-lo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ch8x0w3pYA",
        "outputId": "e34c4c54-b387-47d2-819e-8cdfdeef57ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo já foi baixado, não precisa fazer o download novamente\n",
            "MD5 bate com o esperado\n",
            "CPU times: user 2.07 s, sys: 1.38 s, total: 3.45 s\n",
            "Wall time: 7.49 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "str_arquivo = './collections/msmarco-passage/collectionandqueries.tar.gz'\n",
        "md5_esperado = '31644046b18952c1386cd4564ba2ae69'\n",
        "\n",
        "if not Path(str_arquivo).is_file():\n",
        "  !mkdir collections/msmarco-passage # type: ignore\n",
        "  !wget https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz -P collections/msmarco-passage # type: ignore\n",
        "  !tar xvfz collections/msmarco-passage/collectionandqueries.tar.gz -C collections/msmarco-passage # type: ignore\n",
        "else:\n",
        "  print('Arquivo já foi baixado, não precisa fazer o download novamente')\n",
        "\n",
        "with open(str_arquivo, 'rb') as arquivo:\n",
        "    data = arquivo.read()\n",
        "    md5_arquivo = hashlib.md5(data).hexdigest()\n",
        "    del data\n",
        "    print('MD5 bate com o esperado' if md5_esperado == md5_arquivo else 'MD5 é diferente do esperado, é necessário fazer o download novamente.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybyp0sXvMULz"
      },
      "source": [
        "Os passos seguintes são procedimentos demorados. Por isso a ideia é fazê-los só uma vez para a geração do índice e, depois, guardar o índice já gerado no Google Drive e fazer o download dele diretamente. Por isso, primeiro vou rodar o código aqui para gerar o índice e, depois, comentá-lo. Se necessário (se eu apagar os arquivos do drive por exemplo), depois basta descomentar para gerar novamente.\n",
        "\n",
        "O segundo passo é converter os arquivos da coleção MS MARCO (extensão tsv) para arquivos jsonl do Pyserini (um objeto json por linha). Isso é feito no tutorial usando o script tools/scripts/msmarco/convert_collection_to_jsonl.py . Entretanto, como esse script não existe, primeiro é necessário fazer o download do arquivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SJdaT3UMT5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e84914c-daf1-4006-8f62-39202db1548f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.87 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "if gerar_indice_pyserini:\n",
        "  !wget -O convert_collection_to_jsonl.py https://raw.githubusercontent.com/castorini/anserini-tools/7b84f773225b5973b4533dfa0aa18653409a6146/scripts/msmarco/convert_collection_to_jsonl.py  # type: ignore\n",
        "\n",
        "  !python convert_collection_to_jsonl.py --collection-path collections/msmarco-passage/collection.tsv --output-folder collections/msmarco-passage/collection_jsonl  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWsaMOayQc3B"
      },
      "source": [
        "Agora indexa a coleção:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUs7kz4Qj12",
        "outputId": "17be26f7-b4e8-4f3e-9aa3-760f2f153be6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexes/\n",
            "indexes/lucene-index-msmarco-passage/\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_8.fnm\n",
            "indexes/lucene-index-msmarco-passage/_0.fnm\n",
            "indexes/lucene-index-msmarco-passage/_4.tvx\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_2.tvd\n",
            "indexes/lucene-index-msmarco-passage/_4.fdx\n",
            "indexes/lucene-index-msmarco-passage/_0.nvd\n",
            "indexes/lucene-index-msmarco-passage/_3.tvx\n",
            "indexes/lucene-index-msmarco-passage/_8.fdx\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_4.fdt\n",
            "indexes/lucene-index-msmarco-passage/_6.tvm\n",
            "indexes/lucene-index-msmarco-passage/_7.nvd\n",
            "indexes/lucene-index-msmarco-passage/_2.fnm\n",
            "indexes/lucene-index-msmarco-passage/_2.nvd\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_4.si\n",
            "indexes/lucene-index-msmarco-passage/_1.fnm\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_0.fdt\n",
            "indexes/lucene-index-msmarco-passage/_7.tvx\n",
            "indexes/lucene-index-msmarco-passage/_5.nvd\n",
            "indexes/lucene-index-msmarco-passage/_2.tvm\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_5.si\n",
            "indexes/lucene-index-msmarco-passage/_5.tvd\n",
            "indexes/lucene-index-msmarco-passage/_0.fdx\n",
            "indexes/lucene-index-msmarco-passage/segments_2\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_3.fdm\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_2.si\n",
            "indexes/lucene-index-msmarco-passage/_5.tvm\n",
            "indexes/lucene-index-msmarco-passage/_3.si\n",
            "indexes/lucene-index-msmarco-passage/_8.tvx\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_6.fdx\n",
            "indexes/lucene-index-msmarco-passage/_8.fdm\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_6.fdm\n",
            "indexes/lucene-index-msmarco-passage/_6.si\n",
            "indexes/lucene-index-msmarco-passage/_4.fnm\n",
            "indexes/lucene-index-msmarco-passage/_5.fdx\n",
            "indexes/lucene-index-msmarco-passage/_7.fdx\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_2.nvm\n",
            "indexes/lucene-index-msmarco-passage/_3.nvd\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_7.fnm\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_6.fnm\n",
            "indexes/lucene-index-msmarco-passage/_0.tvm\n",
            "indexes/lucene-index-msmarco-passage/_8.tvm\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_2.fdt\n",
            "indexes/lucene-index-msmarco-passage/_6.nvm\n",
            "indexes/lucene-index-msmarco-passage/_5.fdm\n",
            "indexes/lucene-index-msmarco-passage/_1.si\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_1.fdm\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_5.nvm\n",
            "indexes/lucene-index-msmarco-passage/_3.fdx\n",
            "indexes/lucene-index-msmarco-passage/_4.nvm\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_1.tvm\n",
            "indexes/lucene-index-msmarco-passage/_3.tvd\n",
            "indexes/lucene-index-msmarco-passage/_0.fdm\n",
            "indexes/lucene-index-msmarco-passage/_4.fdm\n",
            "indexes/lucene-index-msmarco-passage/_7.tvd\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_1.nvm\n",
            "indexes/lucene-index-msmarco-passage/_0.si\n",
            "indexes/lucene-index-msmarco-passage/_4.tvd\n",
            "indexes/lucene-index-msmarco-passage/_7.tvm\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_2.tvx\n",
            "indexes/lucene-index-msmarco-passage/_7.fdm\n",
            "indexes/lucene-index-msmarco-passage/_0.tvd\n",
            "indexes/lucene-index-msmarco-passage/_3.nvm\n",
            "indexes/lucene-index-msmarco-passage/_5.fdt\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_7.fdt\n",
            "indexes/lucene-index-msmarco-passage/_6.nvd\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_2.fdm\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/write.lock\n",
            "indexes/lucene-index-msmarco-passage/_8.fdt\n",
            "indexes/lucene-index-msmarco-passage/_4.tvm\n",
            "indexes/lucene-index-msmarco-passage/_0.nvm\n",
            "indexes/lucene-index-msmarco-passage/_3.fdt\n",
            "indexes/lucene-index-msmarco-passage/_2.fdx\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_5.tvx\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_5.fnm\n",
            "indexes/lucene-index-msmarco-passage/_3.tvm\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_8.tvd\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_0.tvx\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_1.nvd\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.doc\n",
            "indexes/lucene-index-msmarco-passage/_4_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_8_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_8.nvm\n",
            "indexes/lucene-index-msmarco-passage/_5_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_1_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.dvd\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_3_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_8.nvd\n",
            "indexes/lucene-index-msmarco-passage/_2_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.pos\n",
            "indexes/lucene-index-msmarco-passage/_3.fnm\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_7.nvm\n",
            "indexes/lucene-index-msmarco-passage/_1.fdx\n",
            "indexes/lucene-index-msmarco-passage/_7_Lucene90_0.tip\n",
            "indexes/lucene-index-msmarco-passage/_6_Lucene90_0.dvm\n",
            "indexes/lucene-index-msmarco-passage/_4.nvd\n",
            "indexes/lucene-index-msmarco-passage/_8.si\n",
            "indexes/lucene-index-msmarco-passage/_7.si\n",
            "indexes/lucene-index-msmarco-passage/_1.fdt\n",
            "indexes/lucene-index-msmarco-passage/_1.tvd\n",
            "indexes/lucene-index-msmarco-passage/_6.tvx\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.tim\n",
            "indexes/lucene-index-msmarco-passage/_6.fdt\n",
            "indexes/lucene-index-msmarco-passage/_1.tvx\n",
            "indexes/lucene-index-msmarco-passage/_0_Lucene90_0.tmd\n",
            "indexes/lucene-index-msmarco-passage/_6.tvd\n",
            "CPU times: user 780 ms, sys: 232 ms, total: 1.01 s\n",
            "Wall time: 1min 31s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "if gerar_indice_pyserini:\n",
        "  # Gera o índice\n",
        "  # Observação: coloquei esse comando em uma linha muito grande pq estava dando um erro de formatação que eu não conseguia tirar...\n",
        "  !python -m pyserini.index.lucene --collection JsonCollection --input collections/msmarco-passage/collection_jsonl --index indexes/lucene-index-msmarco-passage --generator DefaultLuceneDocumentGenerator --threads 9 --storePositions --storeDocvectors --storeRaw # type: ignore\n",
        "\n",
        "  # Compacta o índice num arquivo indexes.tar.gz\n",
        "  !tar -czvf indexes.tar.gz indexes/  # type: ignore\n",
        "\n",
        "  # Copia o arquivo compactado para a pasta do google drive. Se for o caso, é necessário primeiro criar a pasta IA368-DD_deep_learning_busca\n",
        "  !mkdir '/content/drive/My Drive/IA368-DD_deep_learning_busca/'  # type: ignore\n",
        "  !cp indexes.tar.gz '/content/drive/My Drive/IA368-DD_deep_learning_busca/'  # type: ignore\n",
        "else:\n",
        "  # O código abaixo considera que o índice já está no google drive. Basta baixar ele e descompactar:\n",
        "  !cp '/content/drive/My Drive/IA368-DD_deep_learning_busca/indexes.tar.gz' './indexes.tar.gz'  # type: ignore\n",
        "\n",
        "  !tar xvfz indexes.tar.gz  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhuu3B6iaY1a"
      },
      "source": [
        "### III. Usar o BM25 implementado pelo pyserini para buscar queries no TREC-DL 2020\n",
        "\n",
        "Podemos testar reproduzindo os resultados de [Ma et al](https://castorini.github.io/pyserini/2cr/msmarco-v1-passage.html). O nDCG@10 deve ser de 0.4796. Vamos usar os comandos descritos no link:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rRShjNAY9e9",
        "outputId": "751639c2-a294-4982-f763-a4faad71c9fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-08 09:50:56.843427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-08 09:50:58.272931: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:50:58.273067: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:50:58.273093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Setting BM25 parameters: k1=0.9, b=0.4\n",
            "Running dl20 topics, saving to run.dl20.txt...\n",
            "100% 200/200 [00:30<00:00,  6.57it/s]\n",
            "2023-03-08 09:51:36.359347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-08 09:51:37.574485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:51:37.574649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:51:37.574703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run.dl20.txt']\n",
            "Results:\n",
            "ndcg_cut_10           \tall\t0.4796\n",
            "CPU times: user 396 ms, sys: 62 ms, total: 458 ms\n",
            "Wall time: 48.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "!python -m pyserini.search.lucene \\\n",
        "  --threads 16 --batch-size 128 \\\n",
        "  --index indexes/lucene-index-msmarco-passage \\\n",
        "  --topics dl20 \\\n",
        "  --output run.dl20.txt \\\n",
        "  --bm25 --k1 0.9 --b 0.4\n",
        "\n",
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run.dl20.txt  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmLB5rVuf8go"
      },
      "source": [
        "Deu pra reproduzir o resultado do nDCG@10 conforme divulgado (0.4796), até aqui parece que as coisas foram montadas corretamente.\n",
        "\n",
        "Obs.: Na chamada ao pyserini.search.lucene, ao chamar --topics passamos apenas dl20. Na chamada ao trec_eval, passamos dl20-passage. [No exemplo de onde essa chamada foi tirada](https://castorini.github.io/pyserini/2cr/msmarco-v1-passage.html), se fosse usar o dl19 deveria passar dl19-passage nos dois casos parâmetros...\n",
        "\n",
        "Obs 2.: O que a chamada acima faz é rodar todas as queries do tópico dl20 e salvar em um arquivo run.dl20.txt. Em seguida é feita outra chamada passando esse arquivo como parâmetro para a avaliar a métrica nDCG@10.\n",
        "\n",
        "É interessante ver o formato desse arquivo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmVcOFXsQY5i",
        "outputId": "bc579f78-873e-4ca6-9be6-4891e778b5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3505 Q0 3859340 1 14.401300 Anserini\n",
            "3505 Q0 4711746 2 14.132300 Anserini\n",
            "3505 Q0 7207815 3 13.934600 Anserini\n",
            "3505 Q0 3829534 4 13.207600 Anserini\n",
            "3505 Q0 8285660 5 12.672300 Anserini\n",
            "3505 Q0 6834658 6 12.421400 Anserini\n",
            "3505 Q0 3859344 7 12.351500 Anserini\n",
            "3505 Q0 6834656 8 12.307600 Anserini\n",
            "3505 Q0 4409525 9 12.275400 Anserini\n",
            "3505 Q0 7557329 10 12.215300 Anserini\n"
          ]
        }
      ],
      "source": [
        "!head run.dl20.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvOVov0dQ5Dn"
      },
      "source": [
        "Segundo o ChatGPT, esse arquivo deve ser interpretado da seguinte forma:\n",
        "\n",
        "In the Pyserini script you provided, the output file run.dl20.txt will contain the search results for the topics specified in the dl20 file.\n",
        "\n",
        "Each line in the output file corresponds to a single retrieved document for a particular query (i.e., topic). The format of each line is:\n",
        "\n",
        "    [topic_id] Q0 [doc_id] [rank] [score] [run_name]\n",
        "\n",
        "where:\n",
        "\n",
        "- topic_id is the identifier of the topic/query.\n",
        "- Q0 is a fixed value indicating that the query was a topic query.\n",
        "- doc_id is the identifier of the retrieved document.\n",
        "- rank is the rank of the document in the ranked list of retrieved documents for the topic.\n",
        "- score is the retrieval score assigned to the document by the retrieval system for the topic.\n",
        "- run_name is a user-defined identifier for the retrieval run.\n",
        "\n",
        "For example, a typical line in the output file might look like:\n",
        "\n",
        "    301 Q0 doc1234 1 10.5678 my_run_name\n",
        "\n",
        "This line indicates that document doc1234 was retrieved as the top-ranked document for query/topic 301, with a retrieval score of 10.5678, and was assigned the identifier my_run_name for the retrieval run.\n",
        "\n",
        "The output file can be further processed and analyzed using various evaluation metrics and tools, such as trec_eval or pytrec_eval, to compute performance measures such as precision, recall, MAP, and NDCG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPxPWssjQYhv"
      },
      "source": [
        "<br>\n",
        "\n",
        "Agora vamos tentar reproduzir esse resultado usando código. Esse código usou as seguintes fonte: [1](https://github.com/castorini/pyserini/), [2](https://colab.research.google.com/github/castorini/anserini-notebooks/blob/master/pyserini_msmarco_passage_demo.ipynb#scrollTo=03sPnM3wWBfJ).\n",
        "\n",
        "O primeiro passo é obter as queries do tópico dl20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBstpdpCgVCi",
        "outputId": "25ecd4f0-32ec-4f2e-96a1-ab655abae02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 queries total\n",
            "dict_keys([735922, 23849, 514096, 156498, 258062, 703782, 1071750, 436707, 1117817, 1135268, 67316, 132622, 482726, 99005, 655914, 1065636, 1106928, 169208, 246883, 794223, 1104501, 938400, 586148, 1107440, 1108651, 1130705, 1037496, 1134988, 1119543, 1120588, 1064670, 1043135, 1122767, 1127540, 1109850, 449367, 75198, 144862, 735482, 48792, 1107315, 1116380, 1135283, 88495, 1108473, 91576, 914916, 1110678, 660198, 47210, 877809, 1106979, 792635, 918162, 1108466, 1056416, 1113256, 64647, 1119118, 1134939, 883915, 50122, 730539, 999466, 808400, 1105860, 819983, 330501, 1108450, 701453, 166046, 125659, 1122843, 940547, 1126523, 1121879, 1118370, 174463, 1132532, 302846, 1103791, 555530, 330975, 814183, 121171, 611953, 118440, 850358, 273695, 1112142, 177604, 253749, 997622, 197312, 1135413, 1127233, 655526, 519025, 768208, 1132943, 1134207, 332593, 978031, 256942, 452915, 257119, 1134680, 181626, 809525, 1132950, 1131069, 42752, 390360, 1133485, 1127004, 1128456, 1105792, 985594, 206106, 849550, 463271, 537817, 1136769, 1132842, 1051399, 1132044, 1049519, 1117886, 469589, 716113, 911232, 1113042, 1125632, 1125755, 1109699, 708979, 590019, 26703, 1122138, 1126738, 384356, 141630, 801118, 1115210, 1124552, 804066, 605127, 85020, 360721, 435548, 779302, 135802, 318362, 1114993, 1130847, 336901, 227873, 610265, 653399, 583468, 640502, 537060, 1118426, 425632, 405163, 1135626, 1130734, 175920, 53233, 545355, 794429, 1134094, 426175, 1132247, 1133579, 1136962, 1136047, 86606, 1123657, 119821, 1121353, 1109707, 945835, 1136043, 42255, 240158, 1134431, 1030303, 1103153, 1129081, 3505, 444389, 1114286, 1045109, 1114166, 673670, 1108729, 245052, 324585, 543273])\n",
            "\n",
            "Exemplo de query:\n",
            "{'title': 'what is crimp oil'}\n"
          ]
        }
      ],
      "source": [
        "from pyserini.search import get_topics\n",
        "\n",
        "topics = get_topics('dl20')\n",
        "print(f'{len(topics)} queries total')\n",
        "\n",
        "print(topics.keys())\n",
        "print('\\nExemplo de query:')\n",
        "print(topics[735922])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVwstEgCPHBU"
      },
      "source": [
        "Agora podemos criar um LuceneSearcher carregando o índice que foi gerado e fazer uma pesquisa usando os mesmos parâmetros k1 e b para comparar os resultados (nota: bm25, k1=0.9 e b=0.4 já são default do LuceneSearcher, mas é mais claro deixar explícito do código).\n",
        "\n",
        "O resultado é um array de hits, cujo conteúdo pode ser acessado através do atributo raw. Por exemplo, para pesquisar pela mesma query acima (what is crimp oil):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ZMJ5MvRDIkxk",
        "outputId": "c6e81452-6a73-47f0-ad52-af4bbb9b606f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1 9.60990 Definition of crimped in the Definitions.net dictionary. Meaning of crimped. Wha...\n",
            " 2 9.39730 Description: There has always been a debate as to what is the best form of crimp...\n",
            " 3 9.39330 What does crimped mean? Definitions for crimped Here are all the possible meanin...\n",
            " 4 9.20850 Effect of Crimp Depth on Shotshells. Crimp depth of a finished shotshell reload ...\n",
            " 5 8.95510 Crimp Oil is a 100% natural blend of essential oils and plant extracts that aids...\n",
            " 6 8.66260 Directions. 1  Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of ...\n",
            " 7 8.56560 1 Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of aluminum foil...\n",
            " 8 8.53480 Metolius Crimp Oil. 1  A healing massage oil for climbers hands and muscles. 2  ...\n",
            " 9 8.49770 crimped. simple past tense and past participle of crimp The sharp bend had crimp...\n",
            "10 8.47610 Metolius Crimp Oil aids in quick and fast healing of the finger, hand, and wrist...\n",
            "\n",
            "Objeto hits[0].raw (chegando o formato):\n",
            "CPU times: user 938 ms, sys: 38.8 ms, total: 976 ms\n",
            "Wall time: 484 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"id\" : \"7307871\",\\n  \"contents\" : \"Definition of crimped in the Definitions.net dictionary. Meaning of crimped. What does crimped mean? Information and translations of crimped in the most comprehensive dictionary definitions resource on the web.\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from pyserini.search.lucene import LuceneSearcher\n",
        "import json\n",
        "\n",
        "searcher = LuceneSearcher('indexes/lucene-index-msmarco-passage')\n",
        "searcher.set_bm25(k1=float(0.9), b=float(0.4))\n",
        "\n",
        "hits = searcher.search(topics[735922]['title'])\n",
        "\n",
        "# Prints the first 10 hits\n",
        "for i in range(0, 10):\n",
        "    jsondoc = json.loads(hits[i].raw)\n",
        "    print(f'{i+1:2} {hits[i].score:.5f} {jsondoc[\"contents\"][:80]}...')\n",
        "\n",
        "# Verifica o formato do objeto hits:\n",
        "print('\\nObjeto hits[0].raw (chegando o formato):')\n",
        "\n",
        "hits[0].raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwUUET67Ps6N"
      },
      "source": [
        "Agora podemos rodar todas as queries do tópico. O arquivo gerado sobrescreverá o anterior (run.dl20.txt). Como estamos avaliando nDCG@10, vamos pegar apenas os 10 primeiros hits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fElDO11GJw5W",
        "outputId": "aab5d50a-59a2-4a1a-f466-2a72f36af3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 200 queries in total\n",
            "100 queries completed\n",
            "200 queries completed\n",
            "CPU times: user 15 s, sys: 249 ms, total: 15.2 s\n",
            "Wall time: 6.16 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def run_all_queries(file, topics, searcher):\n",
        "    with open(file, 'w') as runfile:\n",
        "        cnt = 0\n",
        "        print('Running {} queries in total'.format(len(topics)))\n",
        "        for id in topics:\n",
        "            query = topics[id]['title']\n",
        "            hits = searcher.search(query, 10) # Gera só os 10 primeiros resultados da query\n",
        "            for i in range(0, len(hits)):\n",
        "                _ = runfile.write('{} Q0 {} {} {:.6f} Anserini\\n'.format(id, hits[i].docid, i+1, hits[i].score))\n",
        "            cnt += 1\n",
        "            if cnt % 100 == 0:\n",
        "                print(f'{cnt} queries completed')\n",
        "\n",
        "run_all_queries('run.dl20.txt', topics, searcher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHBQNh_9RdyR"
      },
      "source": [
        "Novamente, vamos checar o arquivo gerado e ver todas as queries disponíveis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k459vTg9RpJf",
        "outputId": "21f03e33-5a97-4c76-d5cd-5ed7258846e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "735922 Q0 7307871 1 9.609900 Anserini\n",
            "735922 Q0 2766952 2 9.397300 Anserini\n",
            "735922 Q0 7307863 3 9.393300 Anserini\n",
            "735922 Q0 8734268 4 9.208500 Anserini\n",
            "735922 Q0 8626892 5 8.955100 Anserini\n",
            "735922 Q0 5537112 6 8.662600 Anserini\n",
            "735922 Q0 5537109 7 8.565600 Anserini\n",
            "735922 Q0 8626887 8 8.534800 Anserini\n",
            "735922 Q0 7307868 9 8.497700 Anserini\n",
            "735922 Q0 8626890 10 8.476100 Anserini\n",
            "23849 Q0 4348282 1 10.066300 Anserini\n",
            "23849 Q0 2674124 2 9.865500 Anserini\n",
            "\n",
            "Queries:\n",
            "\n",
            "735922\t\twhat is crimp oil\n",
            "23849\t\tare naturalization records public information\n",
            "514096\t\tthe after hours clinic\n",
            "156498\t\tdo google docs auto save\n",
            "258062\t\thow long does it take to remove wisdom tooth\n",
            "703782\t\twhat is a torn disc\n",
            "1071750\t\twhy is pete rose banned from hall of fame\n",
            "436707\t\tlargest known insects\n",
            "1117817\t\twhat does unauthorized act in writing mean\n",
            "1135268\t\tantibiotics for what kind of infection\n",
            "67316\t\tcan fever cause miscarriage early pregnancy\n",
            "132622\t\tdefinition of attempted arson\n",
            "482726\t\tprojective definition\n",
            "99005\t\tconvert sq meter to sq inch\n",
            "655914\t\twhat drives poaching\n",
            "1065636\t\twhy do some places on my scalp feel sore\n",
            "1106928\t\twhen are the four forces that act on an airplane in equilibrium?\n",
            "169208\t\tdoes mississippi have an income tax\n",
            "246883\t\thow long do ticks survive without host\n",
            "794223\t\twhat is scientific definition of cytoplasm\n",
            "1104501\t\twhich hormone increases calcium levels in the blood?\n",
            "938400\t\twhen did family feud come out?\n",
            "586148\t\twhat causes bruises to appear\n",
            "1107440\t\twhat year did knee deep come out funkadelic\n",
            "1108651\t\twhat the best way to get clothes white\n",
            "1130705\t\thow much do a passport\n",
            "1037496\t\twho is rep scalise?\n",
            "1134988\t\tfirst eagle credit union routing number\n",
            "1119543\t\twhat does a psychological screening consist of for egg donors\n",
            "1120588\t\tcaries detection system\n",
            "1064670\t\twhy do hunters pattern their shotguns?\n",
            "1043135\t\twho killed nicholas ii of russia\n",
            "1122767\t\twhat amino produces carnitine\n",
            "1127540\t\tmeaning of shebang\n",
            "1109850\t\twhat language is craith filmed in?\n",
            "449367\t\tmeaning of tattoos around eyes\n",
            "75198\t\tcan uti cause stroke\n",
            "144862\t\tdid prohibition increased crime\n",
            "735482\t\twhat is cow chip t\n",
            "48792\t\tbarclays fca number\n",
            "1107315\t\twhat year were the timberwolves founded\n",
            "1116380\t\twhat is a nonconformity? earth science\n",
            "1135283\t\tembedded payments definition\n",
            "88495\t\tcauses of stroke?\n",
            "1108473\t\twhat time zone is st paul minnesota in\n",
            "91576\t\tchicken as food wikipedia\n",
            "914916\t\twhat type of tissue are bronchioles\n",
            "1110678\t\twhat is the un fao\n",
            "660198\t\twhat food can i take on a plane\n",
            "47210\t\taverage wedding dress alteration cost\n",
            "877809\t\twhat metal are hip replacements made of\n",
            "1106979\t\tdefine pareto chart in statistics\n",
            "792635\t\twhat is rsrq\n",
            "918162\t\twhat was darwin's greatest contribution to evolutionary theory?\n",
            "1108466\t\twhat tissue composes the hypodermis\n",
            "1056416\t\twho was the highest career passer  rating in the nfl\n",
            "1113256\t\twhat is reba mcentire's net worth\n",
            "64647\t\tcan ativan cause coughing\n",
            "1119118\t\twhat does distraint mean?\n",
            "1134939\t\tflyover definition\n",
            "883915\t\twhat other brain proteins can cause dementia\n",
            "50122\t\tbenefit policy in layoff\n",
            "730539\t\twhat is chronometer who invented it\n",
            "999466\t\twhere is velbert\n",
            "808400\t\twhat is the best music maker\n",
            "1105860\t\twhere can the amazon rainforest is located\n",
            "819983\t\twhat is the electric field at\n",
            "330501\t\thow much weight on usps letter\n",
            "1108450\t\tdefine define gallows\n",
            "701453\t\twhat is a statutory deed\n",
            "166046\t\tdoes ethambutol treat bone infection\n",
            "125659\t\tdefine premature babies\n",
            "1122843\t\twhat adobe do you need to create external links in a pdf document\n",
            "940547\t\twhen did rock n roll begin?\n",
            "1126523\t\toutmaneuver definition\n",
            "1121879\t\twhat are the major political parties in great britain? select all that apply.\n",
            "1118370\t\twhat does provisions mean?\n",
            "174463\t\tdog day afternoon meaning\n",
            "1132532\t\taverage annual income data analyst\n",
            "302846\t\thow much caffeine in twinings green tea\n",
            "1103791\t\tdefinition of endorsing\n",
            "555530\t\twhat are best foods to lower cholesterol\n",
            "330975\t\thow much would it cost to install my own wind turbine\n",
            "814183\t\twhat is the data rate of sdtv\n",
            "121171\t\tdefine etruscans\n",
            "611953\t\twhat county is rio hondo tx\n",
            "118440\t\tdefine bmt medical\n",
            "850358\t\twhat is the temperature in venice fl\n",
            "273695\t\thow long will methadone stay in your system\n",
            "1112142\t\twhat is the distance between flat rock michigan and detroit michigan\n",
            "177604\t\teating foods that are considered warm\n",
            "253749\t\thow long does it take for discover to raise limit\n",
            "997622\t\twhere is the show shameless filmed\n",
            "197312\t\tgroup edit policy\n",
            "1135413\t\tdx code for thoracic outlet syndrome\n",
            "1127233\t\tmonk meaning\n",
            "655526\t\twhat does zetia treat\n",
            "519025\t\tthe symptoms of shingles\n",
            "768208\t\twhat is mamey\n",
            "1132943\t\thow long do i cook artichokes for\n",
            "1134207\t\tholidays definition\n",
            "332593\t\thow often to button quail lay eggs\n",
            "978031\t\twhere is berlin center\n",
            "256942\t\thow long does it take to get feeling back after surgery?\n",
            "452915\t\tmetabolic disease signs and symptoms\n",
            "257119\t\thow long does it take to get refund from petsmart\n",
            "1134680\t\tgeneva il median sales price\n",
            "181626\t\testar meaning\n",
            "809525\t\twhat is the botanical name for mango\n",
            "1132950\t\thow long do hormonal headaches last\n",
            "1131069\t\thow many sons robert kraft has\n",
            "42752\t\taverage salary in canada 1985\n",
            "390360\t\tia suffix meaning\n",
            "1133485\t\thow does vitamin c helps\n",
            "1127004\t\tms symptoms ms\n",
            "1128456\t\tis the medicine toradol a narcotic\n",
            "1105792\t\tdefine: geon\n",
            "985594\t\twhere is kampuchea\n",
            "206106\t\thotels in st. louis area\n",
            "849550\t\twhat is the symptoms of croup\n",
            "463271\t\tneptune's distance from earth\n",
            "537817\t\tvitamin e anti scar\n",
            "1136769\t\twhy does lacquered brass tarnish\n",
            "1132842\t\thow long do you stay contagious with the flu\n",
            "1051399\t\twho sings monk theme song\n",
            "1132044\t\thow many bricks per wall\n",
            "1049519\t\twho said no one can make you feel inferior\n",
            "1117886\t\twhat does the word pottery mean\n",
            "469589\t\toracle bind variable example\n",
            "716113\t\twhat is an mbot\n",
            "911232\t\twhat type of conflict does della face in o, henry the gift of the magi\n",
            "1113042\t\twhat is shakespeare's theatre called\n",
            "1125632\t\trouting number for savings bank of maine\n",
            "1125755\t\treigning, definition\n",
            "1109699\t\twhat mental illnesses\n",
            "708979\t\twhat is aids and hiv\n",
            "590019\t\twhat causes muscles to tear\n",
            "26703\t\tarmy dating websites\n",
            "1122138\t\twhat are symptoms of kid\n",
            "1126738\t\tnumber of employees for disa global solutions\n",
            "384356\t\thow to uninstall xbox from windows 10\n",
            "141630\t\tdescribe how muscles and bones work together to produce movement\n",
            "801118\t\twhat is supplemental security income used for\n",
            "1115210\t\twhat is chaff and flare\n",
            "1124552\t\tbriefly describe how the lungs function\n",
            "804066\t\twhat is the actor color?\n",
            "605127\t\twhat county is dexter michigan in\n",
            "85020\t\tcauses for shortness of breath through exertion\n",
            "360721\t\thow to get a free xbox one card\n",
            "435548\t\tlandfill hours\n",
            "779302\t\twhat is onboarding for credit unions\n",
            "135802\t\tdefinition of laudable\n",
            "318362\t\thow much does talent directors get paid a year\n",
            "1114993\t\tconformative definition\n",
            "1130847\t\thow many years you have to go through and school is to become a anesthesiologist\n",
            "336901\t\thow old is vanessa redgrave\n",
            "227873\t\thow does the body oxidize alcohol so it can be eliminated\n",
            "610265\t\twhat county is new york new york in?\n",
            "653399\t\twhat does the weird e mean in math\n",
            "583468\t\twhat carvedilol used for\n",
            "640502\t\twhat does it mean if your tsh is low\n",
            "537060\t\tvillage of burnham\n",
            "1118426\t\twhat does plank owner mean\n",
            "425632\t\tis the a splitboard in skis\n",
            "405163\t\tis caffeine an narcotic\n",
            "1135626\t\tdoes low vitamin cause tingling\n",
            "1130734\t\thow much cornstarch is needed to thicken\n",
            "175920\t\tdriving distance  geneva ny to syracuse\n",
            "53233\t\tbiggest loser challenge\n",
            "545355\t\tweather in novi sad\n",
            "794429\t\twhat is sculpture shape space\n",
            "1134094\t\thotshot members\n",
            "426175\t\tis the duodenum a muscle\n",
            "1132247\t\thow long to cook potato wedges in the oven from frozen\n",
            "1133579\t\thow does granulation tissue start\n",
            "1136962\t\twhy did the ancient egyptians call their land kemet, or black land?\n",
            "1136047\t\tdifference between a company's strategy and business model is\n",
            "86606\t\tcauses of gas in large intestine\n",
            "1123657\t\twalmart phone number linton in\n",
            "119821\t\tdefine curvilinear\n",
            "1121353\t\twhat can you do about discrimination in the workplace in oklahoma city\n",
            "1109707\t\twhat medium do radio waves travel through\n",
            "945835\t\twhen does ace hardware open?\n",
            "1136043\t\tdifference between a hotel and motel\n",
            "42255\t\taverage salary for dental hygienist in nebraska\n",
            "240158\t\thow long are we contagious after we catch a cold.?\n",
            "1134431\t\thead basketball coach at texas a&m.\n",
            "1030303\t\twho is aziz hashim\n",
            "1103153\t\twho is thomas m cooley\n",
            "1129081\t\tin healthcare what does iihi stand for\n",
            "3505\t\thow do they do open heart surgery\n",
            "444389\t\tmagnesium definition chemistry\n",
            "1114286\t\twhat is in the meat group\n",
            "1045109\t\twho owns barnhart crane\n",
            "1114166\t\twhat is it called when your blood becomes too thin\n",
            "673670\t\twhat is a alm\n",
            "1108729\t\twhat temperature and humidity to dry sausage\n",
            "245052\t\thow long do financial institutions keep records after closing\n",
            "324585\t\thow much money do motivational speakers make\n",
            "543273\t\tweather in antigua november\n"
          ]
        }
      ],
      "source": [
        "!head -12 run.dl20.txt\n",
        "\n",
        "print('\\nQueries:\\n')\n",
        "for idx in topics:\n",
        "  print(f'{idx}\\t\\t{topics[idx][\"title\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUYvgIheWUAB"
      },
      "source": [
        "Pra finalizar, vamos calcular o nDCG@10 novamente para confirmar o valor (0.4796):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKcTi4_CKOKP",
        "outputId": "de00d195-a075-4559-9b3b-aafdedf2b7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-08 09:51:59.133785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:51:59.133944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:51:59.133974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run.dl20.txt']\n",
            "Results:\n",
            "ndcg_cut_10           \tall\t0.4796\n",
            "CPU times: user 92.3 ms, sys: 35 ms, total: 127 ms\n",
            "Wall time: 7.67 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run.dl20.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NzpooT1U3B6"
      },
      "source": [
        "### III. Buscador booleano/bag of words\n",
        "\n",
        "\n",
        "Pra implementar o buscador é necessário indexar todos os documentos.\n",
        "\n",
        "Primeiro testei de onde é melhor pegar o conteúdo dos arquivos. Infelizmente não dá pra pegar direto do índice, pois ele só disponibiliza o raw do json convertido a partir do arquivo tsv. Assim, pra acessar o conteúdo de cada documento aqui é necessário primeiro converter pra um dict. Esse processo demorou cerca de 12 minutos. Já acessar diretamente o conteúdo do arquivo collection.tsv leva cerca de 24 segundos apenas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mktz5CG1YiFj"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "# Total de documentos indexados no índice\n",
        "#print(searcher.num_docs)\n",
        "\n",
        "# Testa se é muito demorado iterar em toda a lista de documentos e converter pra json pra acessar uma propriedade\n",
        "#for idx in range(searcher.num_docs):\n",
        "#  doc = searcher.doc(searcher.num_docs-1)\n",
        "#  contents = json.loads(doc.raw())['contents']\n",
        "#  if idx % 100000 == 0:\n",
        "#    print(idx)\n",
        "\n",
        "# Vamos testar também o tempo pra iterar o arquivo collection.csv e acessar o conteúdo de cada documento:\n",
        "# !head collections/msmarco-passage/collection.tsv\n",
        "#with open('collections/msmarco-passage/collection.tsv', encoding='utf-8') as f:\n",
        "#  for idx, line in enumerate(f):\n",
        "#    doc_id, contents = line.rstrip().split('\\t')\n",
        "#    if idx % 100000 == 0:\n",
        "#      print(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay0P5JcvxNdZ"
      },
      "source": [
        "Vamos agora criar uma classe para guardar um índice invertido e, em seguida, indexar os quase 9 milhões de documentos da coleção MS MARCO (obs.: como o processo de gerar o índice é demorado, vamos fazer o esquema de gerar uma vez e salvar no Google Drive. Nas próximas pegamos direto de lá).\n",
        "\n",
        "Observação: O índice está guardando tanto os documentos quanto a quantidade de vezes que o termo ocorre no documento. Por conta de eficiência de memória, a ideia aqui é usar o módulo array. Vou tentar guardar cada inteiro com 4 bytes, mas se não funcionar reduzo o array de ocorrências para 2 bytes. Além disso, para facilitar na hora do TF-IDF, estou guardando um mapa com o total de tokens por documento.\n",
        "\n",
        "Uma coisa interessante é que o ChatGPT indicou que o tipo i/I tinha 4 bytes, sendo que a documentação do módulo diz que esse tipo de dados são 2 bytes. Ou seja, o ChatGPT indica que é um tipo que dá pra guardar as ids dos documentos (cerca de 8 milhões), entretanto o número máximo é de cerca de 65mil (unsigned)..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKsOaJf2p3SE",
        "outputId": "992ae51f-e316-4dbc-f884-3874df0df569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lasdk', 'test', 'braco']\n",
            "0: teste teste teste teste \n",
            "1: alskfj lasdk asf\n",
            "2: lasdk teste braco\n",
            "{'test': {'id_doc': array('L', [0, 2]), 'n_ocorrencias': array('L', [4, 1])}, 'alskfj': {'id_doc': array('L', [1]), 'n_ocorrencias': array('L', [1])}, 'lasdk': {'id_doc': array('L', [1, 2]), 'n_ocorrencias': array('L', [1, 1])}, 'asf': {'id_doc': array('L', [1]), 'n_ocorrencias': array('L', [1])}, 'braco': {'id_doc': array('L', [2]), 'n_ocorrencias': array('L', [1])}}\n",
            "{0: 4, 1: 3, 2: 3}\n",
            "CPU times: user 3.77 ms, sys: 728 µs, total: 4.49 ms\n",
            "Wall time: 3.88 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
        "from collections import Counter\n",
        "import array\n",
        "\n",
        "# Definição de uma classe para índice invertido\n",
        "class IndiceInvertido:\n",
        "\n",
        "  # Recebe 'tokenizar', uma função tokenizadora\n",
        "  def __init__(self, tokenizar = None):\n",
        "    # Cria um índice invertido vazio\n",
        "    self.indice = {}\n",
        "    # Cria um índice de tamanho de documentos vazio\n",
        "    self.tamanho_doc = {}\n",
        "    # Guarda o total de documentos adicionados\n",
        "    self.n_docs = 0\n",
        "\n",
        "    # Se não passou uma função tokenizadora como parâmetro, considera o do Lucene som Porter stemmer:\n",
        "    if (tokenizar is None):\n",
        "      tokenizar = Analyzer(get_lucene_analyzer(stemmer='porter')).analyze\n",
        "    self.tokenizar = tokenizar\n",
        "\n",
        "  def adiciona_doc(self, id_doc, conteudo_doc=None, tokens=None):\n",
        "    if (tokens is None):\n",
        "      tokens = self.tokenizar(conteudo_doc)\n",
        "\n",
        "    contador_tokens_do_documento = Counter(tokens)\n",
        "    for token, n_ocorrencias in contador_tokens_do_documento.items():\n",
        "      # Tenta converter o id do documento para int (ocupa menos memória que uma string)\n",
        "      # Usa um array de 4bytes para e um de 2bytes para o número de ocorrências\n",
        "      int_id_doc = int(id_doc)\n",
        "      self.indice.setdefault(token, {\"id_doc\": array.array(\"L\", []), \"n_ocorrencias\": array.array(\"L\", [])})['id_doc'].append(int_id_doc)\n",
        "      self.indice.setdefault(token, {\"id_doc\": array.array(\"L\", []), \"n_ocorrencias\": array.array(\"L\", [])})['n_ocorrencias'].append(n_ocorrencias)\n",
        "    \n",
        "    self.n_docs += 1\n",
        "    self.tamanho_doc[int_id_doc] = len(tokens)\n",
        "\n",
        "# Testa o índice invertido com os três primeiros documentos da coleção\n",
        "iidx = IndiceInvertido()\n",
        "#conteudo_doc_0 = json.loads(searcher.doc(0).raw())['contents']\n",
        "#conteudo_doc_1 = json.loads(searcher.doc(1).raw())['contents']\n",
        "#conteudo_doc_2 = json.loads(searcher.doc(2).raw())['contents']\n",
        "conteudo_doc_0 = \"teste \" * 4\n",
        "conteudo_doc_1 = \"alskfj lasdk asf\"\n",
        "conteudo_doc_2 = \"lasdk teste braco\"\n",
        "iidx.adiciona_doc(\"0\", conteudo_doc_0)\n",
        "iidx.adiciona_doc(\"1\", conteudo_doc_1)\n",
        "iidx.adiciona_doc(\"2\", conteudo_doc_2)\n",
        "print(iidx.tokenizar(conteudo_doc_2))\n",
        "print(f'0: {conteudo_doc_0}\\n1: {conteudo_doc_1}\\n2: {conteudo_doc_2}\\n{iidx.indice}\\n{iidx.tamanho_doc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YksS1GJdCUwF"
      },
      "source": [
        "Gera o índice e depois salva em um arquivo pickle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkNW158_wg4v",
        "outputId": "33e8a381-9174-4309-e93d-44ec8214c786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copiando arquivo de índice do drive...\n",
            "Copiando arquivo de tamanho do documento do drive...\n",
            "Lendo arquivo de índice...\n",
            "Lendo arquivo de tamanho do documento...\n",
            "CPU times: user 6.24 s, sys: 6.76 s, total: 13 s\n",
            "Wall time: 40.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import pickle\n",
        "\n",
        "iidx_ms_marco = IndiceInvertido()\n",
        "\n",
        "def carregar_indice_invertido_em_iidx_ms_marco():\n",
        "  if gerar_indice_implementado:\n",
        "    # Demorando cerca de 25 min pra gerar o índice\n",
        "    with open('collections/msmarco-passage/collection.tsv', encoding='utf-8') as f:\n",
        "      for idx, line in enumerate(f):\n",
        "        doc_id, contents = line.rstrip().split('\\t')\n",
        "        iidx_ms_marco.adiciona_doc(doc_id, contents)\n",
        "\n",
        "        if idx % 250000 == 0:\n",
        "          print(idx)\n",
        "\n",
        "    print('Finalizou a indexação.')\n",
        "    print('Gerando arquivo de índice:')\n",
        "    with open('iidx_ms_marco.pickle', 'wb') as f:\n",
        "      pickle.dump(iidx_ms_marco.indice, f)\n",
        "    print('Gerando arquivo de tamanho do documento:')\n",
        "    with open('tamanho_doc_ms_marco.pickle', 'wb') as f:\n",
        "      pickle.dump(iidx_ms_marco.tamanho_doc, f)\n",
        "\n",
        "    # Copia arquivos de índice e tamanho do documento para o google drive:\n",
        "    print('Copiando arquivo de índice para Drive')\n",
        "    !cp iidx_ms_marco.pickle '/content/drive/My Drive/IA368-DD_deep_learning_busca/'  # type: ignore\n",
        "    print('Copiando arquivo de tamanho de documento para Drive')\n",
        "    !cp tamanho_doc_ms_marco.pickle '/content/drive/My Drive/IA368-DD_deep_learning_busca/'   # type: ignore\n",
        "\n",
        "  else:\n",
        "    # Demorando cerca de 1min pra copiar as informações do drive e abrir aqui\n",
        "    print('Copiando arquivo de índice do drive...')\n",
        "    !cp '/content/drive/My Drive/IA368-DD_deep_learning_busca/iidx_ms_marco.pickle' './iidx_ms_marco.pickle'  # type: ignore\n",
        "    print('Copiando arquivo de tamanho do documento do drive...')\n",
        "    !cp '/content/drive/My Drive/IA368-DD_deep_learning_busca/tamanho_doc_ms_marco.pickle' './tamanho_doc_ms_marco.pickle'  # type: ignore\n",
        "\n",
        "    # Remonta o índice invertido\n",
        "    print('Lendo arquivo de índice...')\n",
        "    with open('iidx_ms_marco.pickle', 'rb') as f:\n",
        "      iidx_ms_marco.indice = pickle.load(f)\n",
        "    # Remonta o índice de tamanho de documento\n",
        "    print('Lendo arquivo de tamanho do documento...')\n",
        "    with open('tamanho_doc_ms_marco.pickle', 'rb') as f:\n",
        "      iidx_ms_marco.tamanho_doc = pickle.load(f)\n",
        "    # Recalcula o total de documentos\n",
        "    iidx_ms_marco.n_docs = len(iidx_ms_marco.tamanho_doc)\n",
        "\n",
        "# Nos testes durante o desenvolvimento é útil, pois posso ir mudando o índice as vezes. Na versão final nem precisaria\n",
        "carregar_indice_invertido_em_iidx_ms_marco()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg9vnHyDu0dT"
      },
      "source": [
        "\n",
        "Faz alguns testes rápidos com o índice gerado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O4Q6Qjm_adU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c72924-753e-4ecc-8c41-7da66599d48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de documentos com a palavra what: 543257\n",
            "Total de documentos com a palavra oil: 106501\n",
            "Total de documentos no índice: 8841823\n",
            "Id do primeiro documento que tem a palavra what: 0\n",
            "Total de tokens do primeiro documento que tem a palavra what: 30\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total de documentos com a palavra what: {len(iidx_ms_marco.indice['what']['id_doc'] )}\")\n",
        "print(f\"Total de documentos com a palavra oil: {len(iidx_ms_marco.indice['oil']['id_doc'] )}\")\n",
        "print(f\"Total de documentos no índice: {iidx_ms_marco.n_docs}\")\n",
        "print(f\"Id do primeiro documento que tem a palavra what: {iidx_ms_marco.indice['what']['id_doc'][0]}\")\n",
        "print(f\"Total de tokens do primeiro documento que tem a palavra what: {iidx_ms_marco.tamanho_doc[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O exercício pediu um \"buscador booleano/bag of words\". Pra mim não ficou claro se são buscadores distintos ou não. Uma pesquisa no Google e uma conversa com o ChatGPT parece indicar que são coisas iguais e cujo objetivo é retornar uma busca dos documentos que dão match com a query, sem o ranking.\n",
        "\n",
        "Entretanto, é possível também definir ranking também para os documentos. O ChatGPT indicou, por exemplo, fazer o ranking usando TF-IDF ou contar os termos da query que aparecem na lista de documentos final.\n",
        "\n",
        "Como um dos objetivos do exercício é a implementação de um buscador com TF-IDF, vamos deixar pra usá-lo posteriormente. Assim, para simplificar, vamos montar o ranking de acordo se o termo aparece no documento ou não.\n",
        "\n",
        "Por exemplo, suponha que a query seja \"numero primo\" e existem dois documentos retornados assim:\n",
        "\n",
        "1. meu primo gosta de numero primo\n",
        "2. o primo dela viajou\n",
        "\n",
        "No primeiro caso o score será 2, pois tanto a palavra primo quanto a palavra numero aparecem. No documento 2 o score será 1, pois apenas a palavra primo aparece no documento.\n",
        "\n",
        "Note que nessa contagem de palavras há a possibilidade de um outro cálculo do score que será dado pela contagem de ocorrências da palavra. No exemplo acima, o score do documento 1 será 3 (2 para a palavra primo e 1 para a palavra numero) e o score do documento 2 será 1 (a palavra primo aparece apenas uma vez).\n",
        "\n",
        "<br>\n",
        "\n",
        "Para implemenar isso, vamos seguir o exemplo da classe do Lucene e criar uma classe PesquisaSimples que recebe o nosso índice invertido. E aí criamos um método pesquisar que recebe uma query e o tipo de cálculo do score. O tipo pode ser a string \"1\" ou a string \"OCORRENCIA\", ou seja, se for \"1\", cada termo da query contribuirá com 0 ou 1 para o cálculo do score. Se for \"OCORRENCIA\", contribuirá com a quantidade de vezes que ele aparece no documento.\n",
        "\n",
        "<br>\n",
        "\n",
        "Um outro detalhe aqui é o que o método pesquisar também tem um parâmetro chamado remover_stopwords_nltk. Esse parâmetro serve para reduzir ainda mais a query para desconsiderar palavras que são consideradas stopwords na bibliteca NLTK mas que não são na biblioteca do Lucene por padrão. Note que isso não altera o índice, apenas reduz a query. Isso não tem impacto na formulação da pesquisa booleana (mas não pode no caso do TF-IDF, por isso não usaremos essa redução da query lá)."
      ],
      "metadata": {
        "id": "-CsB4t5vNKl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ1KFgGS7H-s",
        "outputId": "7eb15340-a834-4dd9-faf9-9f15f2a6cf14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: what is crimp oil\n",
            "Tokens da query: ['what', 'crimp', 'oil']\n",
            "[(180247, 2), (180248, 2), (281697, 2), (281701, 2), (1240692, 2), (1432224, 2), (1798285, 2), (2342899, 2), (2381629, 2), (2523268, 2)]\n",
            "CPU times: user 82.7 ms, sys: 4.08 ms, total: 86.8 ms\n",
            "Wall time: 85.3 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "class PesquisaSimples:\n",
        "\n",
        "  lista_stopwords_nltk = set([\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])\n",
        "\n",
        "  def __init__(self, indiceInvertido=IndiceInvertido()):\n",
        "    self.indiceInvertido = indiceInvertido\n",
        "    \n",
        "  def tokenizar(self, query):\n",
        "    return self.indiceInvertido.tokenizar(query)\n",
        "\n",
        "  # O tipo de pesquisa pode ser '1' ou 'OCORRENCIA'\n",
        "  def pesquisar(self, query, tipo='1', remover_stopwords_nltk=False):\n",
        "    # Tokeniza a query\n",
        "    tokens = self.tokenizar(query)\n",
        "    if (remover_stopwords_nltk):\n",
        "      tokens = set(tokens).difference(PesquisaSimples.lista_stopwords_nltk)\n",
        "\n",
        "    # Se não tem token para ser pesquisado, retorna conjunto vazio\n",
        "    if (len(tokens) == 0):\n",
        "      return []\n",
        "\n",
        "    # Guarda um dicionário onde a chave é o id do documento e o valor é o score desse documento para a query pesquisada\n",
        "    docs_retornado_com_score = {}\n",
        "\n",
        "    # Na pesquisa booleana vou montar o ranking adicionando 1 se o termo está no documento, 0 caso contrário\n",
        "    # No bag of words estou considerando quantas ocorrências ele aparece em cada documento.\n",
        "    # Isso é feito através da função get_contribuicao_do_score_no_doc\n",
        "    get_contribuicao_do_score_no_doc = (lambda score : 1) if tipo == '1' else (lambda score : score)\n",
        "\n",
        "    # Faz a pesquisa de documentos. Para isso iteramos todos os tokens da query\n",
        "    for token in tokens:\n",
        "\n",
        "      # É possível que a query contenha algum termo que não foi indexado. Se isso ocorrer,\n",
        "      # apenas ignora o termo (já que não tem como saber) e continua...\n",
        "      if token not in self.indiceInvertido.indice:\n",
        "        continue\n",
        "\n",
        "      # Pega a lista de documentos que tem o token e a quantidade de ocorrências que o token\n",
        "      # tem em cada documento:\n",
        "      docs_que_tem_token = self.indiceInvertido.indice[token]['id_doc']\n",
        "      n_ocorrencias_do_token_no_doc = self.indiceInvertido.indice[token]['n_ocorrencias']\n",
        "\n",
        "      # Percorre essa lista conjuntamente. Aqui é que é gerado o score de cada documento\n",
        "      # No caso da pesquisa booleana, vai adicionando 1 caso o documento apareça na query ou não\n",
        "      # No caso de bag of words, vai adicionando o score. Pra não ter que ficar comparando\n",
        "      # toda hora que tipo de pesquisa é e nem para duplicar código em dois métodos, \n",
        "      # estou usando a função get_contribuicao_do_score_no_doc definida antes do loop\n",
        "      for id_doc, n_ocorrencias in zip(docs_que_tem_token, n_ocorrencias_do_token_no_doc):\n",
        "        docs_retornado_com_score[id_doc] = docs_retornado_com_score.get(id_doc, 0) + get_contribuicao_do_score_no_doc(n_ocorrencias)\n",
        "\n",
        "    # Agora converte esse dict em uma lista de tuplas com a chave (id_doc) e valor (score_do_doc)\n",
        "    docs_com_score = list(docs_retornado_com_score.items())\n",
        "\n",
        "    # E ordena do mais relevante para o menos relevante\n",
        "    return sorted(docs_com_score, key=lambda x: x[1], reverse=True)\n",
        "  \n",
        "\n",
        "# Testando com a primeira query:\n",
        "query = topics[735922][\"title\"]\n",
        "print(f'Query: {query}')\n",
        "print(f'Tokens da query: {iidx_ms_marco.tokenizar(query)}')\n",
        "pesquisa_simples = PesquisaSimples(iidx_ms_marco)\n",
        "resultado = pesquisa_simples.pesquisar(query, \"1\", True)\n",
        "print(resultado[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ver os 10 primeiros resultados de uma query trazida pelo BM25 e pelo buscador booleano:"
      ],
      "metadata": {
        "id": "vaLmXqyeSBc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "query = topics[735922]['title']\n",
        "\n",
        "print(f'Pesquisando a query: {query}')\n",
        "\n",
        "# Primeiro pesquisa usando o BM25 do Lucene:\n",
        "searcher = LuceneSearcher('indexes/lucene-index-msmarco-passage')\n",
        "searcher.set_bm25(k1=float(0.9), b=float(0.4))\n",
        "hits = searcher.search(query, k=20)\n",
        "\n",
        "# Agora pesquisa usando o Buscador booleano\n",
        "resultado = pesquisa_simples.pesquisar(query, \"1\", True)\n",
        "\n",
        "print('\\nResultado do LuceneSearcher (BM-25):\\n')\n",
        "for i in range(0, 10):\n",
        "  jsondoc = json.loads(hits[i].raw)\n",
        "  print(f'{i+1:2} {hits[i].score:.5f} {jsondoc[\"contents\"][:160]}...')\n",
        "\n",
        "print('\\nResultado do PesquisaSimples:\\n')\n",
        "print(f'Documentos retornados: {resultado[0:10]}\\n')\n",
        "for i in range(0, 10):\n",
        "  # PesquisaSimples indexa em int. O índice do sistema do Lucene, em string\n",
        "  str_id_doc = str(resultado[i][0])\n",
        "  score = resultado[i][1]\n",
        "  conteudo = json.loads(searcher.doc(str_id_doc).raw())['contents']\n",
        "  print(f'{score:.5f} {conteudo[:160]}...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV29rNMBSA5h",
        "outputId": "c7093670-ff17-44a3-8501-521747025b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesquisando a query: what is crimp oil\n",
            "\n",
            "Resultado do LuceneSearcher (BM-25):\n",
            "\n",
            " 1 9.60990 Definition of crimped in the Definitions.net dictionary. Meaning of crimped. What does crimped mean? Information and translations of crimped in the most compreh...\n",
            " 2 9.39730 Description: There has always been a debate as to what is the best form of crimping - hexagonal or indent. There is no straight answer as the crimping method de...\n",
            " 3 9.39330 What does crimped mean? Definitions for crimped Here are all the possible meanings and translations of the word crimped....\n",
            " 4 9.20850 Effect of Crimp Depth on Shotshells. Crimp depth of a finished shotshell reload is an important dimension to monitor for consistent ballistics and safe loads. T...\n",
            " 5 8.95510 Crimp Oil is a 100% natural blend of essential oils and plant extracts that aids in the recovery of climbing-related injuries....\n",
            " 6 8.66260 Directions. 1  Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of aluminum foil, shiny side up, place the pork loin. 3  Rub it with the canola oil...\n",
            " 7 8.56560 1 Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of aluminum foil, shiny side up, place the pork loin. 3  Rub it with the canola oil and crimp th...\n",
            " 8 8.53480 Metolius Crimp Oil. 1  A healing massage oil for climbers hands and muscles. 2  Reduces pain and swelling in tendons, joints and muscles. 3  100% natural blend ...\n",
            " 9 8.49770 crimped. simple past tense and past participle of crimp The sharp bend had crimped the pipe so almost no water could get through. Adjective . crimped (comparati...\n",
            "10 8.47610 Metolius Crimp Oil aids in quick and fast healing of the finger, hand, and wrist....\n",
            "\n",
            "Resultado do PesquisaSimples:\n",
            "\n",
            "Documentos retornados: [(180247, 2), (180248, 2), (281697, 2), (281701, 2), (1240692, 2), (1432224, 2), (1798285, 2), (2342899, 2), (2381629, 2), (2523268, 2)]\n",
            "\n",
            "2.00000 How to Make It. 1  Preheat grill to medium. Cut 6 12-by-18-inch pieces of heavy-duty foil. 2  In a large bowl, whisk oil, vinegar, garlic, seasoned salt and pep...\n",
            "2.00000 How to Make It. 1  Preheat grill to medium. 2  In a large bowl, whisk oil, vinegar, garlic, seasoned salt and pepper. 3  Fold long sides of foil toward each oth...\n",
            "2.00000 For recycling enthusiasts, the recyclability of container caps, lids and tops can offer hours of stimulating conversation. For everyone else, the question of wh...\n",
            "2.00000 Metal caps from glass jars. The top can be recycled as long as itâs placed in the recycling bin separate from the jar. Examples: tops from pasta sauce jars, j...\n",
            "2.00000 1 Stir together the flour, sugar, and salt in a 9 inch pie pan, and make a well in the center. 2  Pour the oil and rice milk into the well, then mix with a fork...\n",
            "2.00000 1 Preheat grill to medium (or bake in oven at 375Â°). 2  Place one chicken breast on 10x10 piece of heavy aluminum foil. 3  Brush each breast with olive oil, se...\n",
            "2.00000 Preparation. 1  Mix flour, salt, turmeric and curry powder in a large bowl. 2  Heat oil in a deep skillet over medium heat and add scallions, onion, garlic and ...\n",
            "2.00000 Technically speaking, it is not wool but many refer to it as such. A whole fleece consists of two coats: guard hair and down. Guard hair is thick and without cr...\n",
            "2.00000 Precut, Fast-Roast Method. Preheat oven to 450 degrees. Place beets (peeled and cut into 1/2-inch wedges) on a large piece of foil on a baking sheet. Drizzle wi...\n",
            "2.00000 ISO 9001:2008 certified manufacturer & distributor of hydraulic hose. Features include synthetic & oil resistant tubes & covers, crimp-on couplings. Industries ...\n",
            "CPU times: user 298 ms, sys: 18.5 ms, total: 316 ms\n",
            "Wall time: 407 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define um método para rodar todas as 200 queries de teste do TREC DL 2020:"
      ],
      "metadata": {
        "id": "MU_O50c0Xtz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCRZ7HZNCliY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773b4950-c370-4b2a-dbad-6dccd8937deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
            "Wall time: 13.4 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def run_all_queries_pesquisa_simples(file, topics, pesquisaSimples, tipo, remover_stopwords_nltk=False):\n",
        "  with open(file, 'w') as runfile:\n",
        "    cnt = 0\n",
        "    print('Running {} queries in total'.format(len(topics)))\n",
        "    for id in topics:\n",
        "      query = topics[id]['title']\n",
        "      hits = pesquisa_simples.pesquisar(query, tipo, remover_stopwords_nltk)\n",
        "      for i in range(0, min(len(hits), 30)): # Pega os primeiros 30 resultados\n",
        "        _ = runfile.write('{} Q0 {} {} {:.6f} '.format(id, hits[i][0], i+1, hits[i][1]) + \"TIPO_\" + tipo + '\\n')\n",
        "      cnt += 1\n",
        "      if cnt % 100 == 0:\n",
        "        print(f'{cnt} queries completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSWI6fTZ82CS",
        "outputId": "3300b302-494c-44ad-c07f-58f2bc0d6504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando pesquisa simples considerando que o score é um por termo...\n",
            "Running 200 queries in total\n",
            "100 queries completed\n",
            "200 queries completed\n",
            "2023-03-08 09:54:21.033893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:54:21.034041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:54:21.034068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-pesquisa-simples_score_um_por_termo.dl20.txt']\n",
            "Results:\n",
            "ndcg_cut_10           \tall\t0.3412\n",
            "CPU times: user 1min 29s, sys: 2.92 s, total: 1min 32s\n",
            "Wall time: 1min 40s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "print('Rodando pesquisa simples considerando que o score é um por termo...')\n",
        "run_all_queries_pesquisa_simples('run-pesquisa-simples_score_um_por_termo.dl20.txt', topics, pesquisa_simples, '1', True)\n",
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run-pesquisa-simples_score_um_por_termo.dl20.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp0BjWBX83Xr",
        "outputId": "223fc248-d304-4ab7-ba7c-5ee6b0e96182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando pesquisa simples considerando que o score é o total de ocorrências dos termos da query...\n",
            "Running 200 queries in total\n",
            "100 queries completed\n",
            "200 queries completed\n",
            "2023-03-08 09:56:20.077229: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:56:20.077398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 09:56:20.077427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-pesquisa-simples_score_ocorrencia_por_termo.dl20.txt']\n",
            "Results:\n",
            "ndcg_cut_10           \tall\t0.0509\n",
            "CPU times: user 1min 47s, sys: 3.75 s, total: 1min 51s\n",
            "Wall time: 1min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "print('Rodando pesquisa simples considerando que o score é o total de ocorrências dos termos da query...')\n",
        "run_all_queries_pesquisa_simples('run-pesquisa-simples_score_ocorrencia_por_termo.dl20.txt', topics, pesquisa_simples, 'bow', True)\n",
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run-pesquisa-simples_score_ocorrencia_por_termo.dl20.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IV. Buscador com TF-IDF e BM25\n",
        "\n",
        "O buscador com TF-IDF foi implementado na classe PesquisaComTFIDF. Essa classe inicia igual a classe PesquisaSimples, recebendo um objeto do tipo IndiceInvertido (já com o índice calculado). Além disso, recebe os parâmetros k1 e b.\n",
        "\n",
        "A partir daí, o construtor chama a função precalcula_idf para fazer o cálculo do IDF para todos os termos presentes no índice. Esse cálculo é rápido, então é bem tranquilo fazer isso no construtor.\n",
        "\n",
        "Note que a estrutura do objeto IndiceInvertido.indice é: \n",
        "\n",
        "    {\n",
        "      \"token\": {\n",
        "        \"id_doc\": array.array contendo as ids dos documentos,\n",
        "        \"n_ocorrencias\": array.array contendo quantas ocorrências o token aparece no documento equivalente\n",
        "      }\n",
        "    }\n",
        "\n",
        "Podemos alterar essa estrutura para já computar o IDF e deixar ele no índice junto com as outras informações:\n",
        "\n",
        "    {\n",
        "      \"token\": {\n",
        "        \"id_doc\": array.array contendo as ids dos documentos,\n",
        "        \"n_ocorrencias\": array.array contendo quantas ocorrências o token aparece no documento equivalente\n",
        "        \"idf\": int\n",
        "        \"tf_idf\": dict contendo o score do tf_idf para o par token/documento\n",
        "        \"bm25\": dict contendo o score calculado pelo BM25 para o par token/documento\n",
        "      }\n",
        "    }\n",
        "\n",
        "Note acima que, além do idf calculado no construtor foi inserido também uma chave \"tf_idf\". Essa chave é o cálculo do tf_idf para todo par token/doc. No nosso caso não há necessidade de fazer isso no índice todo logo de uma vez ao inicializar o buscador. Isso deixaria a inicialização um pouco lenta. O que é feito é, ao se deparar com um termo de pesquisa pela primeira vez, calcula-se o tf_idf de todos os documentos que tem aquele termo e salva igual na estrutura acima. Na próxima vez que o termo de pesquisa aparece, o termo já está calculado e pode ser recuperado do cache. O efeito desse cache foi a redução do tempo no cálculo nas 200 queries de ~9 minutos para ~6:30 minutos.\n",
        "\n"
      ],
      "metadata": {
        "id": "qW09mvKhrNXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import math\n",
        "\n",
        "class PesquisaComTFIDF:\n",
        "\n",
        "  def __init__(self, indiceInvertido=IndiceInvertido(), k1 = 0.9, b = 0.4, adicionar_ao_idf = 0):\n",
        "    self.indiceInvertido = indiceInvertido\n",
        "    self.adicionar_ao_idf = adicionar_ao_idf\n",
        "    self.calcula_tam_medio_doc_no_indice()\n",
        "    self.k1 = k1\n",
        "    self.b = b\n",
        "    self.precalcula_idf()\n",
        "  \n",
        "  def calcula_tam_medio_doc_no_indice(self):\n",
        "    self.avgdl = sum(self.indiceInvertido.tamanho_doc.values()) / self.indiceInvertido.n_docs\n",
        "\n",
        "  def precalcula_idf(self):\n",
        "    # Número de documento do corpus está presente no objeto indiceInvertido\n",
        "    N = self.indiceInvertido.n_docs\n",
        "    # Varre todos os tokens do índice. Os tokens são as chaves do indiceInvertido.indice\n",
        "    for token in self.indiceInvertido.indice.keys():\n",
        "      # O número de documentos que possui o token é calculado pelo tamanho da lista de id_doc:\n",
        "      n_doc_token = len(self.indiceInvertido.indice[token]['id_doc'])\n",
        "      # Isso já é o suficiente pra calcular o idf\n",
        "      idf_token = math.log( ((self.indiceInvertido.n_docs - n_doc_token + 0.5)/(n_doc_token + 0.5)) + self.adicionar_ao_idf )\n",
        "      # E agora, vamos colocar essa informação no índice\n",
        "      self.indiceInvertido.indice[token]['idf'] = idf_token\n",
        "\n",
        "  def calcula_tf_idf_para_um_token_e_salva(self, token):\n",
        "    # O cálculo do tf_idf exibe apenas multiplicar o idf do termo (que já temos calculado) pelo tf(termo, documento)\n",
        "    # A fórmula do tf = a frequência do termo no documento dividido pelo total de termos do documento\n",
        "    # Logo, tf_idf = idf * frequencia_token_no_doc / tamanho_doc\n",
        "    #             - o idf do token já está precalculado e consta do índice: self.indiceInvertido.indice[token]['idf']\n",
        "    #             - o tamanho_doc também já consta do índice: self.indiceInvertido.tamanho_doc[id_doc] (para certo id_doc)\n",
        "    #             - a frequência do token no documento também consta do índice: self.indiceInvertido.indice[token]['n_ocorrencias']\n",
        "    # Juntando tudo:\n",
        "    # Recupera o idf\n",
        "    idf_token = self.indiceInvertido.indice[token]['idf']\n",
        "    # Calcula o tf_idf\n",
        "    zip_id_freq = zip(self.indiceInvertido.indice[token]['id_doc'], self.indiceInvertido.indice[token]['n_ocorrencias'])\n",
        "    #tf_idf = { id_doc: idf_token * freq_token_no_doc / self.indiceInvertido.tamanho_doc[id_doc] for (id_doc, freq_token_no_doc) in zip_id_freq ]}\n",
        "    tf_idf = array.array('f', [idf_token * freq_token_no_doc / self.indiceInvertido.tamanho_doc[id_doc] for (id_doc, freq_token_no_doc) in zip_id_freq ])\n",
        "    # Salva o tf_idf no índice\n",
        "    self.indiceInvertido.indice[token]['tf_idf'] = tf_idf\n",
        "\n",
        "  def calcula_bm25_para_um_token_e_salva(self, token):\n",
        "    # O cálculo do BM25 para determinada query é a multiplicação do idf pela frequência do termo no documento * (k1 + 1)\n",
        "    # Além disso, é dividido pela frequencia do termo no documento + k1 * (1 - b + b * tamanho_doc/avgdl)\n",
        "    # Para não ter que ficar fazendo várias multiplicações/divisões, vamos resolver o que dá pra resolver antes.\n",
        "    # Sobre isso, o denominador fica: k1 - k1*b + k1*b*tamanho_doc/avgdl\n",
        "    # Então precisamos de três variáveis:\n",
        "    #         idf_x_k1_mais_1 = idf*(k1 + 1)\n",
        "    #         k1_menos_k1_x_b = k1 - k1*b\n",
        "    #         k1_x_b_d_avgdl = k1*b/avgdl\n",
        "    idf_x_k1_mais_1 = self.indiceInvertido.indice[token]['idf']*(self.k1 + 1)\n",
        "    k1_menos_k1_x_b = self.k1 - self.k1*self.b\n",
        "    k1_x_b_d_avgdl = self.k1 * self.b / self.avgdl\n",
        "\n",
        "    # Juntando tudo, podemos calcular o score pelo BM25\n",
        "    zip_id_freq = zip(self.indiceInvertido.indice[token]['id_doc'], self.indiceInvertido.indice[token]['n_ocorrencias'])\n",
        "    #bm25 = { id_doc: idf_x_k1_mais_1 * freq_token_no_doc / (freq_token_no_doc + k1_menos_k1_x_b + k1_x_b_d_avgdl*self.indiceInvertido.tamanho_doc[id_doc]) for (id_doc, freq_token_no_doc) in zip_id_freq }\n",
        "    bm25 = array.array('f', [ idf_x_k1_mais_1 * freq_token_no_doc / (freq_token_no_doc + k1_menos_k1_x_b + k1_x_b_d_avgdl*self.indiceInvertido.tamanho_doc[id_doc]) for (id_doc, freq_token_no_doc) in zip_id_freq ])\n",
        "    # Salva o bm25 no índice\n",
        "    self.indiceInvertido.indice[token]['bm25'] = bm25\n",
        "\n",
        "  def tokenizar(self, query):\n",
        "    return self.indiceInvertido.tokenizar(query)\n",
        "\n",
        "  def pesquisar(self, query, metodo = 'tf_idf'):\n",
        "    # Tokeniza a query\n",
        "    tokens = self.tokenizar(query)\n",
        "\n",
        "    # Se não tem token para ser pesquisado, retorna conjunto vazio\n",
        "    if (len(tokens) == 0):\n",
        "      return []\n",
        "\n",
        "    # Guarda um dicionário onde a chave é o id do documento e o valor é o score desse documento para a query pesquisada\n",
        "    docs_retornado_com_score = Counter({})\n",
        "\n",
        "    # Função para o cálculo de score\n",
        "    funcao_calc_salvar_scores_docs_deste_token = self.calcula_tf_idf_para_um_token_e_salva if metodo == 'tf_idf' else self.calcula_bm25_para_um_token_e_salva\n",
        "\n",
        "    # Faz a pesquisa de documentos. Para isso iteramos todos os tokens da query\n",
        "    for token in tokens:\n",
        "      # É possível que a query contenha algum termo que não foi indexado. Se isso ocorrer,\n",
        "      # entende-se que a frequência desse token em qualquer documento é 0, já que não pode ser encontrado\n",
        "      if token not in self.indiceInvertido.indice:\n",
        "        continue\n",
        "\n",
        "      # Pega a lista de documentos que será analisado\n",
        "      docs_que_tem_token = self.indiceInvertido.indice[token]['id_doc']\n",
        "      \n",
        "      # Se for a primeira vez que esse token é pesquisado, é necessário calcular o tf_idf relacionado\n",
        "      # a ele e salvar. Se já tiver sido feito antes, já podemos buscar o cálculo pronto (que funciona\n",
        "      # como um cache. Isso é útil no caso de várias pesquisas seguidas)\n",
        "      if metodo not in self.indiceInvertido.indice[token].keys():\n",
        "        funcao_calc_salvar_scores_docs_deste_token(token)\n",
        "      score_dos_docs_deste_token = self.indiceInvertido.indice[token][metodo]\n",
        "\n",
        "      # Agora já temos calculado o tf_idf de todos os documentos desse token. Só adiciona ao acumulador de score atual\n",
        "      # docs_retornado_com_score += score_dos_docs_deste_token -> Se fosse usar dict direto no índice seria assim, mas a memória não está aguentando guardar os scores de ambos\n",
        "      for id_doc, score_par_doc_token in zip(docs_que_tem_token, score_dos_docs_deste_token):\n",
        "        docs_retornado_com_score[id_doc] += score_par_doc_token\n",
        "\n",
        "    # Agora converte esse dict em uma lista de tuplas com a chave (id_doc) e valor (score_do_doc)\n",
        "    docs_com_score = list(docs_retornado_com_score.items())\n",
        "\n",
        "    # E ordena do mais relevante para o menos relevante\n",
        "    return sorted(docs_com_score, key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "gX_9srMewOG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fad92d-4bc9-48ce-bad2-2ec2aa5fe371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.31 ms, sys: 0 ns, total: 1.31 ms\n",
            "Wall time: 1.39 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para testar a implementação do BM25, vamos refazer o exercício anterior. São 5 documentos e o resultado do score esperado para o BM25 (considerando adicionar_ao_idf = 1) é:\n",
        "\n",
        "5. primo gosta numero primo. 0,953423382\n",
        "1. numero primo distante. 0,848369848\n",
        "4. primo bagunceiro. 0,636667008\n",
        "2. numero natural grande. 0,295230582\n",
        "3. grande numero dourado escorregadio. 0,260989921\n",
        "\n",
        "Para o TF-IDF é:\n",
        "\n",
        "5. primo gosta numero primo. 0,3415\n",
        "1. numero primo distante. 0,27566\n",
        "4. primo bagunceiro. 0,2695\n",
        "2. numero natural grande. 0,096\n",
        "3. grande numero dourado escorregadio. 0,072\n",
        "\n",
        "E o IDF com adicionar +1:\n",
        "\n",
        "numero: 0,287\n",
        "primo: 0,539\n",
        "\n",
        "Testando o código:"
      ],
      "metadata": {
        "id": "WmNoRbzfZ2fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iidx_numero_primo = IndiceInvertido()\n",
        "iidx_numero_primo.adiciona_doc(1, \"numero primo distante\")\n",
        "iidx_numero_primo.adiciona_doc(2, \"numero natural grande\")\n",
        "iidx_numero_primo.adiciona_doc(3, \"grande numero dourado escorregadio\")\n",
        "iidx_numero_primo.adiciona_doc(4, \"primo bagunceiro\")\n",
        "iidx_numero_primo.adiciona_doc(5, \"primo gosta numero primo\")\n",
        "\n",
        "pesquisa_com_tf_idf = PesquisaComTFIDF(iidx_numero_primo, k1 = 1.2, b = 0.75, adicionar_ao_idf = 1)\n",
        "resultado = pesquisa_com_tf_idf.pesquisar(\"numero primo\", 'bm25')\n",
        "\n",
        "print('Pesquisa com BM25:\\n')\n",
        "for (id, score) in resultado:\n",
        "  print(id, score)\n",
        "\n",
        "resultado = pesquisa_com_tf_idf.pesquisar(\"numero primo\", 'tf_idf')\n",
        "print('\\n\\nPesquisa com TF-IDF:\\n')\n",
        "for (id, score) in resultado:\n",
        "  print(id, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_s2wz4bgNmB",
        "outputId": "6e411761-27c0-4803-b922-8b194b1022dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesquisa com BM25:\n",
            "\n",
            "5 0.953423410654068\n",
            "1 0.848369836807251\n",
            "4 0.636667013168335\n",
            "2 0.29523056745529175\n",
            "3 0.2609899342060089\n",
            "\n",
            "\n",
            "Pesquisa com TF-IDF:\n",
            "\n",
            "5 0.3414187803864479\n",
            "1 0.27555952966213226\n",
            "4 0.2694982588291168\n",
            "2 0.09589402377605438\n",
            "3 0.07192052155733109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pra testar, vamos usar a mesma query anterior e comparar com o BM-25 do Pyserini com mesmos parâmetros:"
      ],
      "metadata": {
        "id": "9cj3pqpc2-2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "query = topics[735922]['title']\n",
        "\n",
        "print(f'Pesquisando a query no BM25 do Lucene: {query}')\n",
        "\n",
        "# Primeiro pesquisa usando o BM25 do Lucene:\n",
        "searcher = LuceneSearcher('indexes/lucene-index-msmarco-passage')\n",
        "searcher.set_bm25(k1=float(0.9), b=float(0.4))\n",
        "hits = searcher.search(query, k=20)\n",
        "\n",
        "# Agora pesquisa usando o Buscador com TFIDF\n",
        "pesquisa_com_tf_idf = PesquisaComTFIDF(iidx_ms_marco, 1)\n",
        "resultado = pesquisa_com_tf_idf.pesquisar(query, 'bm25')\n",
        "\n",
        "print('\\nResultado do LuceneSearcher (BM-25):\\n')\n",
        "for i in range(0, 10):\n",
        "  jsondoc = json.loads(hits[i].raw)\n",
        "  print(f'{i+1:2} {hits[i].score:.5f} {jsondoc[\"contents\"][:160]}...')\n",
        "\n",
        "print('\\nResultado da pesquisa implementada:\\n')\n",
        "print(f'Documentos retornados: {resultado[0:10]}')\n",
        "for i in range(0, 10):\n",
        "  # PesquisaSimples indexa em int. O índice do sistema do Lucene, em string\n",
        "  str_id_doc = str(resultado[i][0])\n",
        "  score = resultado[i][1]\n",
        "  conteudo = json.loads(searcher.doc(str_id_doc).raw())['contents']\n",
        "  print(f'{score:.5f} {conteudo[:160]}...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI6sobq929fi",
        "outputId": "dd0f0496-2c19-4d9a-e852-797ade852c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesquisando a query no BM25 do Lucene: what is crimp oil\n",
            "\n",
            "Resultado do LuceneSearcher (BM-25):\n",
            "\n",
            " 1 9.60990 Definition of crimped in the Definitions.net dictionary. Meaning of crimped. What does crimped mean? Information and translations of crimped in the most compreh...\n",
            " 2 9.39730 Description: There has always been a debate as to what is the best form of crimping - hexagonal or indent. There is no straight answer as the crimping method de...\n",
            " 3 9.39330 What does crimped mean? Definitions for crimped Here are all the possible meanings and translations of the word crimped....\n",
            " 4 9.20850 Effect of Crimp Depth on Shotshells. Crimp depth of a finished shotshell reload is an important dimension to monitor for consistent ballistics and safe loads. T...\n",
            " 5 8.95510 Crimp Oil is a 100% natural blend of essential oils and plant extracts that aids in the recovery of climbing-related injuries....\n",
            " 6 8.66260 Directions. 1  Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of aluminum foil, shiny side up, place the pork loin. 3  Rub it with the canola oil...\n",
            " 7 8.56560 1 Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of aluminum foil, shiny side up, place the pork loin. 3  Rub it with the canola oil and crimp th...\n",
            " 8 8.53480 Metolius Crimp Oil. 1  A healing massage oil for climbers hands and muscles. 2  Reduces pain and swelling in tendons, joints and muscles. 3  100% natural blend ...\n",
            " 9 8.49770 crimped. simple past tense and past participle of crimp The sharp bend had crimped the pipe so almost no water could get through. Adjective . crimped (comparati...\n",
            "10 8.47610 Metolius Crimp Oil aids in quick and fast healing of the finger, hand, and wrist....\n",
            "\n",
            "Resultado da pesquisa implementada:\n",
            "\n",
            "Documentos retornados: [(7307871, 18.741530895233154), (7307863, 18.269158601760864), (2766952, 18.214536428451538), (8734268, 17.923676013946533), (8626892, 17.233316898345947), (7307868, 16.81580924987793), (8734275, 16.596885681152344), (5537112, 16.570748329162598), (2766953, 16.487895965576172), (1428024, 16.41642189025879)]\n",
            "18.74153 Definition of crimped in the Definitions.net dictionary. Meaning of crimped. What does crimped mean? Information and translations of crimped in the most compreh...\n",
            "18.26916 What does crimped mean? Definitions for crimped Here are all the possible meanings and translations of the word crimped....\n",
            "18.21454 Description: There has always been a debate as to what is the best form of crimping - hexagonal or indent. There is no straight answer as the crimping method de...\n",
            "17.92368 Effect of Crimp Depth on Shotshells. Crimp depth of a finished shotshell reload is an important dimension to monitor for consistent ballistics and safe loads. T...\n",
            "17.23332 Crimp Oil is a 100% natural blend of essential oils and plant extracts that aids in the recovery of climbing-related injuries....\n",
            "16.81581 crimped. simple past tense and past participle of crimp The sharp bend had crimped the pipe so almost no water could get through. Adjective . crimped (comparati...\n",
            "16.59689 It is a separate crimp die that makes a crimp similar to the roll crimp for revolver cartridges and a taper crimp for semi-auto cartridges. It includes a carbid...\n",
            "16.57075 Directions. 1  Heat your oven to 225 degrees Fahrenheit. 2  On a large sheet of aluminum foil, shiny side up, place the pork loin. 3  Rub it with the canola oil...\n",
            "16.48790 These range from the terminal fold-over. tab type of crimp to the single indent crimp, the. dual indenter crimp, the three indenter crimp, hex. crimps, and, ï¬...\n",
            "16.41642 Using Crimp Tubes: To secure them to the jewelry wire, crimp the wire with a crimping tool. The tool has two stations. The first station puts a crimp in the cri...\n",
            "CPU times: user 5 s, sys: 412 ms, total: 5.41 s\n",
            "Wall time: 5.42 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E agora rodar na base de TREC DL 20 e ver o resultado:"
      ],
      "metadata": {
        "id": "cAtNtfrn4S5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def run_all_queries_pesquisa_com_tf_idf(file, topics, pesquisa_com_tf_idf, metodo = 'tf_idf'):\n",
        "  with open(file, 'w') as runfile:\n",
        "    cnt = 0\n",
        "    print('Running {} queries in total'.format(len(topics)))\n",
        "    for id in topics:\n",
        "      query = topics[id]['title']\n",
        "      hits = pesquisa_com_tf_idf.pesquisar(query, metodo)\n",
        "      for i in range(0, min(len(hits), 30)): # Pega os primeiros 30 resultados\n",
        "        _ = runfile.write('{} Q0 {} {} {:.6f} PESQUISA_'.format(id, hits[i][0], i+1, hits[i][1]) + metodo + '\\n')\n",
        "      cnt += 1\n",
        "      if cnt % 10 == 0:\n",
        "        print(f'{cnt} queries completed')\n"
      ],
      "metadata": {
        "id": "7-WpM06K4YGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bd866f-60c9-4540-c9f2-aad49cdd88e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.06 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print('Rodando pesquisa com TF-IDF...')\n",
        "run_all_queries_pesquisa_com_tf_idf('run-pesquisa-com-tf-idf.dl20.txt', topics, pesquisa_com_tf_idf)\n",
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run-pesquisa-com-tf-idf.dl20.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbk-OfJJ4irF",
        "outputId": "f780dd10-0257-4ea2-8321-4bced6ce56a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando pesquisa com TF-IDF...\n",
            "Running 200 queries in total\n",
            "10 queries completed\n",
            "20 queries completed\n",
            "30 queries completed\n",
            "40 queries completed\n",
            "50 queries completed\n",
            "60 queries completed\n",
            "70 queries completed\n",
            "80 queries completed\n",
            "90 queries completed\n",
            "100 queries completed\n",
            "110 queries completed\n",
            "120 queries completed\n",
            "130 queries completed\n",
            "140 queries completed\n",
            "150 queries completed\n",
            "160 queries completed\n",
            "170 queries completed\n",
            "180 queries completed\n",
            "190 queries completed\n",
            "200 queries completed\n",
            "2023-03-08 10:03:10.681800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 10:03:10.681964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 10:03:10.681994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-pesquisa-com-tf-idf.dl20.txt']\n",
            "Results:\n",
            "ndcg_cut_10           \tall\t0.1574\n",
            "CPU times: user 6min 26s, sys: 12.9 s, total: 6min 39s\n",
            "Wall time: 6min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print('Rodando pesquisa com BM25...')\n",
        "run_all_queries_pesquisa_com_tf_idf('run-pesquisa-com-bm25.dl20.txt', topics, pesquisa_com_tf_idf, 'bm25')\n",
        "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run-pesquisa-com-bm25.dl20.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbUL5tkDNFfZ",
        "outputId": "63e960d8-355d-4e15-8920-432d2f1e1033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rodando pesquisa com BM25...\n",
            "Running 200 queries in total\n",
            "10 queries completed\n",
            "20 queries completed\n",
            "30 queries completed\n",
            "40 queries completed\n",
            "50 queries completed\n",
            "60 queries completed\n",
            "70 queries completed\n",
            "80 queries completed\n",
            "90 queries completed\n",
            "100 queries completed\n",
            "110 queries completed\n",
            "120 queries completed\n",
            "130 queries completed\n",
            "140 queries completed\n",
            "150 queries completed\n",
            "160 queries completed\n",
            "170 queries completed\n",
            "180 queries completed\n",
            "190 queries completed\n",
            "200 queries completed\n",
            "2023-03-08 10:10:06.105814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 10:10:06.105967: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-08 10:10:06.105995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
            "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
            "Skipping download.\n",
            "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/root/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-pesquisa-com-bm25.dl20.txt']\n",
            "Results:\n",
            "ndcg_cut_10           \tall\t0.4823\n",
            "CPU times: user 6min 39s, sys: 10.6 s, total: 6min 50s\n",
            "Wall time: 6min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNyjHNr9PuKE"
      },
      "source": [
        "### V. Conclusões\n",
        "\n",
        "<br>\n",
        "\n",
        "#### V.A Resultados consolidados\n",
        "\n",
        "Neste exercício a base TREC DL-2020 foi avaliada com o Pyserini usando 5 buscadores:\n",
        "\n",
        "1. O primeiro usou o BM25 do Lucene com parâmetros (k1, b) = (0.9, 0.4). Esses não são os valores que maximizam os resultados para a base, mas foram escolhidos para replicar o trabalho de [Ma et al](https://castorini.github.io/pyserini/2cr/msmarco-v1-passage.html).\n",
        "\n",
        "2. O segundo buscador foi o buscador booleano implementado que adiciona ao cálculo do score 1 ou 0 dependendo se o termo está presente no documento ou não.\n",
        "\n",
        "3. O terceiro buscador analisado foi o mesmo que o anterior, mas configurado para adicionar n ao cálculo do score, onde n é a quantidade de vezes que a palavra pesquisa aparece no documento.\n",
        "\n",
        "4. O quarto foi a implementação do TF-IDF. Nesse caso, utilizei o IDF somando + 1 ao operando do logaritmo para usar a mesma formulação que o Lucene usa (esse é um parâmetro configurável na implementação).\n",
        "\n",
        "5. O último foi um buscador BM25 com a formulação padrão com (k1, b) = (0.9, 0.4).\n",
        "\n",
        "Os resultados obtidos para cada buscador considerando a métrica nDCG@10 e o tempo de execução para executar 200 queries e avaliar o resultado foram (o tempo foi coletado em uma rodada sequencial deste caderno e deve ser visto apenas para comparação entre eles numa comparação mais grosseira) :\n",
        "\n",
        "<center>\n",
        "\n",
        "| Buscador              | nDCG@10 | Tempo de execução |\n",
        "|-----------------------|---------|-------------------|\n",
        "| Lucene BM25           | 0.4796  | 6.47s             |\n",
        "| Buscador booleano (1) | 0.3427  | 1min 26s          |\n",
        "| Buscador booleano (n) | 0.0509  | 1min 39s          |\n",
        "| Buscador com TF-IDF   | 0.1574  | 6min 15s          |\n",
        "| Buscador BM25         | 0.4823  | 6min 9s           |\n",
        "\n",
        "\n",
        "</center>\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "A primeira observação relevante é que o buscador booleano que leva em consideração o total de ocorrências da palavra no documento tem um resultado muito ruim. Isso possivelmente ocorre porque documentos grandes vão ter os termos da query aparecendo várias vezes, fazendo com que documentos grandes sejam sempre privilegiados no resultado simplesmente por terem palavras demais. Ou seja, considerar unicamente a frequência absoluta de termos é algo que traz danos a busca.\n",
        "\n",
        "Uma outra questão é que o buscador booleano usou mais stopwords que o TF-IDF e BM25. Isso teve um impacto muito grande no booleano. Enquanto o nDCG@10 estava na casa dos 0.19 enquanto usava apenas o pré-processamento do Lucene, ao considerar também as stopwords do NLTK houve melhora para ~0.34.\n",
        "\n",
        "Em relação ao buscador do BM25  implementado, eu esperava que o resultado obtido fosse exatamente o mesmo. Entretanto, houve diferença no resultado. Apesar de terem ordenação parecidas, o score que eu obtive foi bem diferente do calculado no Lucene.\n",
        "\n",
        "Ainda sobre o TF-IDF, uma questão interessante que surgiu aqui é que o resultado de ~0.15 poderia ser aumentado para essa coleção de documentos se, em vez de IDF, usássemos IDF^2.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### V.B Dificuldades encontradas e como foram solucionadas\n",
        "\n",
        "Geração do índice invertido:\n",
        "\n",
        "- Na criação do índice invertido, usei uma estrutura de dict para associar a cada token uma lista de documentos em que aquele token era encontrado. A lista era um tipo list() e, os elementos, string. Esse processo ocupou muita memória, mas estava funcionando.\n",
        "\n",
        "- O segundo passo na criação do índice foi inserir também a informação de quantas vezes o token aparece naquele documento. A tentativa inicial foi usar list() de int(), mas houve estouro de memória (ambiente com 25 GB).\n",
        "\n",
        "- O estouro da memória foi resolvido após alterar a lista de ids de string para int. Como cada id de documento é numérico, não houve problemas nisso. Assim foi possível gerar essas informações em memória. Entretanto a memória estourou após tentar gravar o índice em arquivo.\n",
        "\n",
        "- Após diversas alternativas foi possível corrigir isso alterando o tipo de dados de list() para array.array(). Houve redução significativa da memória ocupada (mais de 50%), o que possibilitou salvar o índice em arquivo e posteriormente carregá-lo.\n",
        "\n",
        "Lentidão no buscador do TF-IDF:\n",
        "\n",
        "- Na primeira implementação funcional do buscador, como o cálculo do IDF é rápido, o construtor do buscador já calculava o IDF para todos os termos e armazenava. Entretanto, o cálculo do TF para cada termo da query era feito sempre que uma query era apresentada. O resultado final foi que a busca nas 200 queries estava levando cerca de 9 minutos para finalizar.\n",
        "\n",
        "- Como muitas palavras (tokens) são usadas em várias queries (e essas palavras ainda costumam aparecer em muitos documentos), havia um desperdício recalculando o TF de um par query/documento sempre que um termo era apresentado. Isso foi resolvido criando no índice um cache para o cálculo do TF. Quando um termo é apresentado ao buscador pela primeira vez ele faz o cálculo e armazena no índice. Quando já tem, pega direto do índice. Isso reduziu o tempo para ~ 6:30 minutos.\n",
        "\n",
        "- Após a retirada do loop de algumas somas e multiplicações do cálculo do TF, o tempo reduziu para menos de 6 minutos, ou seja, em média menos de 2 segundos por query.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### V.C Dúvidas\n",
        "\n",
        "1. Como tratar termos que aparecem mais de uma vez na query? Na implementação feita, se um termo aparece duas vezes na query o score dele é contado duas vezes. Quais os impactos disso?\n",
        "\n",
        "<br>\n",
        "\n",
        "#### V.D Ideias de colegas\n",
        "\n",
        "Usei as seguintes ideias dos colegas:\n",
        "\n",
        "- Guardar o índice no Google Drive: conversa de Marcus Borela e Júlia Tessler.\n",
        "\n",
        "- Uso do wget para download do script que faz a conversão de tsv para json: notebook do Gustavo Bartz\n",
        "\n",
        "- Uso de stopwords do NLTK para diminuir a query (usada na pesquisa booleana): conversa com Monique Monteiro"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "ZNyjHNr9PuKE"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}